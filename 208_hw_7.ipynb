{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36dd73bf",
   "metadata": {},
   "source": [
    "# Курс Спортивный анализ данных. Платформа Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f66a5",
   "metadata": {},
   "source": [
    "# Практическое задание урока 7. Тюнинг гиперпараметров, построение ансамблей алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4e18f",
   "metadata": {},
   "source": [
    "Чтобы было больше времени на выполнение курсовой работы, задание выполнить на наборе данных для соревнования:\n",
    "Тестовая выборка - это выборка для применения модели и загрузки на ЛБ.\n",
    "\n",
    "1.\tОбучить алгоритмы LightGBM и XGBoost, получить OOF прогнозы, оценить корреляцию прогнозов на обучающей выборке. Применить модели на тестовую выборку и оценить корреляцию.\n",
    "2.\tУсреднить прогнозы с помощью арифмитического среднего, геометрического среднего и усреднить ранги, сделать выводы о качестве отдельных моделей и о качестве комбинации.\n",
    "3.\tОбучить CatBoost, получить OOF прогнозы и выполнить задание 1 для трех моделей.\n",
    "4.\tВыполнить задание 2 для трех моделей.\n",
    "5.\t(опция) Объединить OOF-прогнозы для трех моделей и обучить алгоритм Логистической регрессии (и любой другой, на ваше усмотрение). Сделать выводы о достигаемом качестве, сравнить достигаемое качество с качеством отдельных моделей и моделей, полученных в п.2 и п.4.\n",
    "6.\t(опция) Обучить алгоритм RandomForest (желательно подтюнить параметры) и добавить к построенным ранее моделям. Выполнить задание 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8069fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import gmean\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803e9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(dataset_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Считывание данных и вывод основной информации о наборе данных.\n",
    "    \n",
    "    Parametrs\n",
    "    ---------\n",
    "    dataset_path: str\n",
    "        Название файла\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    data: pandas.core.frame.DataFrame\n",
    "        Загруженный набор данных в pandas.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    data_root = Path('D:/DS_materials/208_kaggle/data_comp/')\n",
    "    dataset = pd.read_csv(f'{data_root}/{dataset_path}')\n",
    "    dataset.columns = [col.lower() for col in dataset.columns]\n",
    "    print(f\"{dataset_path} shape: {dataset.shape[0]} rows, {dataset.shape[1]} cols\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "794a75d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_cross_validation(params, X, y, cv, categorical = None):\n",
    "    \"\"\"\n",
    "    Кросс-валидация для модели catbooost.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        Словарь гиперпараметров модели.\n",
    "\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признаков для обучения модели.\n",
    "\n",
    "    y: pandas.core.frame.Series\n",
    "        Вектор целевой переменной для обучения модели.\n",
    "\n",
    "    cv: KFold or StratifiedKFold generator.\n",
    "        Объект KFold / StratifiedKFold для определения\n",
    "        стратегии кросс-валидации модели.\n",
    "\n",
    "    categorical: str, optional, default = None\n",
    "        Список категориальных признаков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    estimators: list\n",
    "        Список с объектами обученной модели.\n",
    "\n",
    "    oof_preds: np.array\n",
    "        Вектор OOF-прогнозов.\n",
    "\n",
    "    \"\"\"\n",
    "    estimators, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "\n",
    "    print(f\"{time.ctime()}, Cross-Validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "    if categorical:\n",
    "        X[categorical] = X[categorical].astype(str)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        model = cb.CatBoostClassifier(**params)\n",
    "        model.fit(\n",
    "            x_train, y_train, categorical,\n",
    "            eval_set=[(x_train, y_train), (x_valid, y_valid)]\n",
    "        )\n",
    "        oof_preds[valid_idx] = model.predict_proba(x_valid)[:, 1]\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimators.append(model)\n",
    "\n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    return estimators, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9400f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_cross_validation(params, fit_params, X, y, cv):\n",
    "    \"\"\"\n",
    "    Кросс-валидация для модели catbooost.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        Словарь гиперпараметров модели.\n",
    "\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признаков для обучения модели.\n",
    "\n",
    "    y: pandas.core.frame.Series\n",
    "        Вектор целевой переменной для обучения модели.\n",
    "\n",
    "    cv: KFold or StratifiedKFold generator.\n",
    "        Объект KFold / StratifiedKFold для определения\n",
    "        стратегии кросс-валидации модели.\n",
    "\n",
    "    categorical: str, optional, default = None\n",
    "        Список категориальных признаков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    estimators: list\n",
    "        Список с объектами обученной модели.\n",
    "\n",
    "    oof_preds: np.array\n",
    "        Вектор OOF-прогнозов.\n",
    "\n",
    "    \"\"\"\n",
    "    estimators, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "\n",
    "    print(f\"{time.ctime()}, Cross-Validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(\n",
    "            x_train, y_train,\n",
    "            eval_set=[(x_train, y_train), (x_valid, y_valid)],\n",
    "            **fit_params\n",
    "        )\n",
    "        oof_preds[valid_idx] = model.predict_proba(x_valid)[:, 1]\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimators.append(model)\n",
    "\n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    return estimators, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfd3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_cross_validation(params, fit_params, X, y, cv):\n",
    "    \"\"\"\n",
    "    Кросс-валидация для модели catbooost.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        Словарь гиперпараметров модели.\n",
    "\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признаков для обучения модели.\n",
    "\n",
    "    y: pandas.core.frame.Series\n",
    "        Вектор целевой переменной для обучения модели.\n",
    "\n",
    "    cv: KFold or StratifiedKFold generator.\n",
    "        Объект KFold / StratifiedKFold для определения\n",
    "        стратегии кросс-валидации модели.\n",
    "\n",
    "    categorical: str, optional, default = None\n",
    "        Список категориальных признаков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    estimators: list\n",
    "        Список с объектами обученной модели.\n",
    "\n",
    "    oof_preds: np.array\n",
    "        Вектор OOF-прогнозов.\n",
    "\n",
    "    \"\"\"\n",
    "    estimators, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "\n",
    "    print(f\"{time.ctime()}, Cross-Validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "    #X[categorical] = X[categorical].astype(str)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            x_train, y_train,\n",
    "            eval_set=[(x_train, y_train), (x_valid, y_valid)],\n",
    "            **fit_params\n",
    "        )\n",
    "        oof_preds[valid_idx] = model.predict_proba(x_valid)[:, 1]\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimators.append(model)\n",
    "\n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    return estimators, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65373629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cat_feats(train, test, categorial):\n",
    "    for feature in categorial:\n",
    "        le = LabelEncoder()\n",
    "        train[feature] = le.fit_transform(train[feature].fillna('null'))\n",
    "        test[feature] = le.transform(test[feature].fillna('null'))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94ab512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_profile_features(X: pd.DataFrame, copy: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Создание признаков на основе профиля клиентов.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признаков с исходным профилем клиента.\n",
    "\n",
    "    copy: bool, optional, default = True\n",
    "        Флаг использования копии датафрейма X.\n",
    "        Опциональный параметр, по умолчанию, равен True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_transformed: pandas.core.frame.DataFrame\n",
    "        Расширенная матрица признаков с профилем клиентов.\n",
    "\n",
    "    \"\"\"\n",
    "    if copy:\n",
    "        X = X.copy()\n",
    "        \n",
    "        \n",
    "    X[\"days_on_last_job\"] = X[\"days_on_last_job\"].replace(365243, np.nan)\n",
    "    bki_flags = [flag for flag in X.columns if \"amt_req_credit_bureau\" in flag]\n",
    "    X[\"bki_requests_count\"] = X[bki_flags].sum(axis=1)\n",
    "    X[\"bki_kurtosis\"] = X[bki_flags].kurtosis(axis=1)\n",
    "\n",
    "    X[\"external_scoring_prod\"] = X[\"external_scoring_rating_1\"] * X[\"external_scoring_rating_2\"] * X[\"external_scoring_rating_3\"]\n",
    "    X[\"external_scoring_weighted\"] = X.external_scoring_rating_1 * 2 + X.external_scoring_rating_2 * 1 + X.external_scoring_rating_3 * 3\n",
    "\n",
    "    for function_name in [\"min\", \"max\", \"mean\", \"nanmedian\", \"var\"]:\n",
    "        feature_name = \"external_scoring_rating_{}\".format(function_name)\n",
    "        X[feature_name] = eval(\"np.{}\".format(function_name))(\n",
    "            X[[\"external_scoring_rating_1\", \"external_scoring_rating_2\", \"external_scoring_rating_3\"]], axis=1\n",
    "            )\n",
    "\n",
    "\n",
    "    # Отношение между основными фин. показателями\n",
    "    X['ratio_credit_to_annuity'] = X['amount_credit'] / X['amount_annuity']\n",
    "    X[\"ratio_annuity_to_salary\"] = X['amount_annuity'] / X['total_salary']\n",
    "    X['ratio_credit_to_salary'] = X['amount_credit'] / X['total_salary']\n",
    "\n",
    "    X[\"ratio_salary_to_per_family_size\"] = X[\"total_salary\"] / X[\"family_size\"]\n",
    "\n",
    "    # Отношение фин. показателей к возрасту и временным фичам\n",
    "    X[\"ratio_annuity_to_age\"] = X[\"amount_annuity\"] / X[\"age\"]\n",
    "    X[\"ratio_credit_to_age\"] = X[\"amount_credit\"] / X[\"age\"]\n",
    "    X[\"ratio_salary_to_age\"] = X[\"total_salary\"] / X[\"age\"]\n",
    "    X[\"ratio_salary_to_experience\"] = X[\"total_salary\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_credit_to_experience\"] = X[\"amount_credit\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_annuity_to_experience\"] = X[\"amount_annuity\"] / X[\"days_on_last_job\"]\n",
    "\n",
    "    # Отношение временных признаков\n",
    "    X[\"ratio_age_to_experience\"] = X[\"age\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_salary_to_region_population\"] = X[\"total_salary\"] * X[\"region_population\"]\n",
    "    X[\"ratio_car_to_experience\"] = X[\"own_car_age\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_car_to_age\"] = X[\"own_car_age\"] / X[\"age\"]\n",
    "\n",
    "    # Произведение фин. показателей кредита на вероятность дефолта\n",
    "    # Такая штука называется математическим ожиданием дефолта или ожидаемыми потерями\n",
    "    X[\"expected_total_loss_1\"] = X[\"external_scoring_rating_1\"] * X[\"amount_credit\"]\n",
    "    X[\"expected_total_loss_2\"] = X[\"external_scoring_rating_2\"] * X[\"amount_credit\"]\n",
    "    X[\"expected_total_loss_3\"] = X[\"external_scoring_rating_3\"] * X[\"amount_credit\"]\n",
    "    X[\"expected_monthly_loss_1\"] = X[\"external_scoring_rating_1\"] * X[\"amount_annuity\"]\n",
    "    X[\"expected_monthly_loss_2\"] = X[\"external_scoring_rating_2\"] * X[\"amount_annuity\"]\n",
    "    X[\"expected_monthly_loss_3\"] = X[\"external_scoring_rating_3\"] * X[\"amount_annuity\"]\n",
    "\n",
    "    \"\"\"\n",
    "    # Сделать конкатенацию признаков, рассматривая их как категориальные\n",
    "    features_1 = ['childrens', 'family_size']\n",
    "    for feature in features_1:\n",
    "        X[feature] = X[feature].astype('str')\n",
    "    \n",
    "    X[\"gender_childrens\"] = X['gender'] + \" | \" + X['childrens']\n",
    "    X[\"gender_family_status\"] = X['gender'] + \" | \" + X['family_status']    \n",
    "    X[\"gender_family_size\"] = X['gender'] + \" | \" + X['family_size'] \n",
    "    X[\"gender_childrens_family_status\"] = X['gender_childrens'] + \" | \" + X['family_status']  \n",
    "    X[\"gender_childrens_family_size\"] = X['gender_childrens'] + \" | \" + X['family_size']   \n",
    "    X[\"gender_family_status_family_size\"] = X['gender_family_status'] + \" | \" + X['family_size']       \n",
    "    X[\"family_status_family_size\"] = X['family_status'] + \" | \" + X['family_size']  \n",
    "    X[\"childrens_family_size\"] = X['childrens'] + \" | \" + X['family_size']\n",
    "    X[\"childrens_family_status\"] = X['childrens'] + \" | \" + X['family_status']  \n",
    "    X[\"childrens_family_status_family_size\"] = X['childrens'] + \" | \" + X['family_status_family_size']  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Сделать FrequencyEncoder для категориальных признаков\n",
    "    features_2 = ['gender', 'childrens', 'family_status', 'family_size']   \n",
    "    for feature in features_2:\n",
    "        freq_enc = X[feature].value_counts(normalize=True)\n",
    "        X[feature + \"_freq_enc\"] = X[feature].map(freq_enc)    \n",
    "          \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb60236",
   "metadata": {},
   "source": [
    "# Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b451e5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv shape: 110093 rows, 3 cols\n",
      "test.csv shape: 165141 rows, 2 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_number</th>\n",
       "      <th>target</th>\n",
       "      <th>name_contract_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123687442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123597908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_number  target name_contract_type\n",
       "0           123687442     0.0               Cash\n",
       "1           123597908     1.0               Cash"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = get_input(\"train.csv\")\n",
    "test = get_input(\"test.csv\")\n",
    "\n",
    "data = pd.concat([train, test], axis=0)\n",
    "data = data.reset_index(drop=True)\n",
    "data.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1029a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_profile.csv shape: 250000 rows, 24 cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1113: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_number</th>\n",
       "      <th>gender</th>\n",
       "      <th>childrens</th>\n",
       "      <th>total_salary</th>\n",
       "      <th>amount_credit</th>\n",
       "      <th>amount_annuity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>family_status</th>\n",
       "      <th>region_population</th>\n",
       "      <th>age</th>\n",
       "      <th>days_on_last_job</th>\n",
       "      <th>own_car_age</th>\n",
       "      <th>flag_phone</th>\n",
       "      <th>flag_email</th>\n",
       "      <th>family_size</th>\n",
       "      <th>external_scoring_rating_1</th>\n",
       "      <th>external_scoring_rating_2</th>\n",
       "      <th>external_scoring_rating_3</th>\n",
       "      <th>amt_req_credit_bureau_hour</th>\n",
       "      <th>amt_req_credit_bureau_day</th>\n",
       "      <th>amt_req_credit_bureau_week</th>\n",
       "      <th>amt_req_credit_bureau_mon</th>\n",
       "      <th>amt_req_credit_bureau_qrt</th>\n",
       "      <th>amt_req_credit_bureau_year</th>\n",
       "      <th>bki_requests_count</th>\n",
       "      <th>bki_kurtosis</th>\n",
       "      <th>external_scoring_prod</th>\n",
       "      <th>external_scoring_weighted</th>\n",
       "      <th>external_scoring_rating_min</th>\n",
       "      <th>external_scoring_rating_max</th>\n",
       "      <th>external_scoring_rating_mean</th>\n",
       "      <th>external_scoring_rating_nanmedian</th>\n",
       "      <th>external_scoring_rating_var</th>\n",
       "      <th>ratio_credit_to_annuity</th>\n",
       "      <th>ratio_annuity_to_salary</th>\n",
       "      <th>ratio_credit_to_salary</th>\n",
       "      <th>ratio_salary_to_per_family_size</th>\n",
       "      <th>ratio_annuity_to_age</th>\n",
       "      <th>ratio_credit_to_age</th>\n",
       "      <th>ratio_salary_to_age</th>\n",
       "      <th>ratio_salary_to_experience</th>\n",
       "      <th>ratio_credit_to_experience</th>\n",
       "      <th>ratio_annuity_to_experience</th>\n",
       "      <th>ratio_age_to_experience</th>\n",
       "      <th>ratio_salary_to_region_population</th>\n",
       "      <th>ratio_car_to_experience</th>\n",
       "      <th>ratio_car_to_age</th>\n",
       "      <th>expected_total_loss_1</th>\n",
       "      <th>expected_total_loss_2</th>\n",
       "      <th>expected_total_loss_3</th>\n",
       "      <th>expected_monthly_loss_1</th>\n",
       "      <th>expected_monthly_loss_2</th>\n",
       "      <th>expected_monthly_loss_3</th>\n",
       "      <th>gender_freq_enc</th>\n",
       "      <th>childrens_freq_enc</th>\n",
       "      <th>family_status_freq_enc</th>\n",
       "      <th>family_size_freq_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123666076</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>Incomplete higher</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>8560</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.329471</td>\n",
       "      <td>0.236315</td>\n",
       "      <td>0.678568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.052832</td>\n",
       "      <td>2.930959</td>\n",
       "      <td>0.236315</td>\n",
       "      <td>0.678568</td>\n",
       "      <td>0.414784</td>\n",
       "      <td>0.329471</td>\n",
       "      <td>0.036237</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>78750.0</td>\n",
       "      <td>1.577103</td>\n",
       "      <td>31.542056</td>\n",
       "      <td>18.399533</td>\n",
       "      <td>101.678502</td>\n",
       "      <td>174.306004</td>\n",
       "      <td>8.7153</td>\n",
       "      <td>5.526146</td>\n",
       "      <td>1270.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88957.124333</td>\n",
       "      <td>63804.966560</td>\n",
       "      <td>183213.275945</td>\n",
       "      <td>4447.856217</td>\n",
       "      <td>3190.248328</td>\n",
       "      <td>9160.663797</td>\n",
       "      <td>0.65858</td>\n",
       "      <td>0.70004</td>\n",
       "      <td>0.097008</td>\n",
       "      <td>0.514472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123423688</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>536917.5</td>\n",
       "      <td>28467.0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>23187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.442295</td>\n",
       "      <td>0.802745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.875000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.442295</td>\n",
       "      <td>0.802745</td>\n",
       "      <td>0.622520</td>\n",
       "      <td>0.622520</td>\n",
       "      <td>0.032481</td>\n",
       "      <td>18.86105</td>\n",
       "      <td>0.105433</td>\n",
       "      <td>1.988583</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>1.227714</td>\n",
       "      <td>23.155971</td>\n",
       "      <td>11.644456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5466.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>237475.743779</td>\n",
       "      <td>431008.094056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12590.802122</td>\n",
       "      <td>22851.755462</td>\n",
       "      <td>0.65858</td>\n",
       "      <td>0.70004</td>\n",
       "      <td>0.639384</td>\n",
       "      <td>0.514472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_number gender  childrens  total_salary  amount_credit  \\\n",
       "0           123666076      F          0      157500.0       270000.0   \n",
       "1           123423688      F          0      270000.0       536917.5   \n",
       "\n",
       "   amount_annuity                education_level   family_status  \\\n",
       "0         13500.0              Incomplete higher  Civil marriage   \n",
       "1         28467.0  Secondary / secondary special         Married   \n",
       "\n",
       "   region_population    age  days_on_last_job  own_car_age  flag_phone  \\\n",
       "0           0.008068   8560            1549.0          NaN           1   \n",
       "1           0.020246  23187               NaN          NaN           0   \n",
       "\n",
       "   flag_email  family_size  external_scoring_rating_1  \\\n",
       "0           0          2.0                   0.329471   \n",
       "1           0          2.0                        NaN   \n",
       "\n",
       "   external_scoring_rating_2  external_scoring_rating_3  \\\n",
       "0                   0.236315                   0.678568   \n",
       "1                   0.442295                   0.802745   \n",
       "\n",
       "   amt_req_credit_bureau_hour  amt_req_credit_bureau_day  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "\n",
       "   amt_req_credit_bureau_week  amt_req_credit_bureau_mon  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "\n",
       "   amt_req_credit_bureau_qrt  amt_req_credit_bureau_year  bki_requests_count  \\\n",
       "0                        1.0                         2.0                 3.0   \n",
       "1                        1.0                         1.0                 2.0   \n",
       "\n",
       "   bki_kurtosis  external_scoring_prod  external_scoring_weighted  \\\n",
       "0      1.428571               0.052832                   2.930959   \n",
       "1     -1.875000                    NaN                        NaN   \n",
       "\n",
       "   external_scoring_rating_min  external_scoring_rating_max  \\\n",
       "0                     0.236315                     0.678568   \n",
       "1                     0.442295                     0.802745   \n",
       "\n",
       "   external_scoring_rating_mean  external_scoring_rating_nanmedian  \\\n",
       "0                      0.414784                           0.329471   \n",
       "1                      0.622520                           0.622520   \n",
       "\n",
       "   external_scoring_rating_var  ratio_credit_to_annuity  \\\n",
       "0                     0.036237                 20.00000   \n",
       "1                     0.032481                 18.86105   \n",
       "\n",
       "   ratio_annuity_to_salary  ratio_credit_to_salary  \\\n",
       "0                 0.085714                1.714286   \n",
       "1                 0.105433                1.988583   \n",
       "\n",
       "   ratio_salary_to_per_family_size  ratio_annuity_to_age  ratio_credit_to_age  \\\n",
       "0                          78750.0              1.577103            31.542056   \n",
       "1                         135000.0              1.227714            23.155971   \n",
       "\n",
       "   ratio_salary_to_age  ratio_salary_to_experience  \\\n",
       "0            18.399533                  101.678502   \n",
       "1            11.644456                         NaN   \n",
       "\n",
       "   ratio_credit_to_experience  ratio_annuity_to_experience  \\\n",
       "0                  174.306004                       8.7153   \n",
       "1                         NaN                          NaN   \n",
       "\n",
       "   ratio_age_to_experience  ratio_salary_to_region_population  \\\n",
       "0                 5.526146                            1270.71   \n",
       "1                      NaN                            5466.42   \n",
       "\n",
       "   ratio_car_to_experience  ratio_car_to_age  expected_total_loss_1  \\\n",
       "0                      NaN               NaN           88957.124333   \n",
       "1                      NaN               NaN                    NaN   \n",
       "\n",
       "   expected_total_loss_2  expected_total_loss_3  expected_monthly_loss_1  \\\n",
       "0           63804.966560          183213.275945              4447.856217   \n",
       "1          237475.743779          431008.094056                      NaN   \n",
       "\n",
       "   expected_monthly_loss_2  expected_monthly_loss_3  gender_freq_enc  \\\n",
       "0              3190.248328              9160.663797          0.65858   \n",
       "1             12590.802122             22851.755462          0.65858   \n",
       "\n",
       "   childrens_freq_enc  family_status_freq_enc  family_size_freq_enc  \n",
       "0             0.70004                0.097008              0.514472  \n",
       "1             0.70004                0.639384              0.514472  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_profile = get_input(\"client_profile.csv\")\n",
    "client_profile = create_client_profile_features(client_profile)\n",
    "client_profile.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ff7d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(\n",
    "    client_profile, how=\"left\", on=\"application_number\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e02cbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data[\"target\"].isnull()\n",
    "features_to_drop = [\"application_number\", \"target\"]\n",
    "\n",
    "train, test = data.loc[~mask], data.loc[mask]\n",
    "\n",
    "target, test_id = train[\"target\"], test[\"application_number\"]\n",
    "train = train.drop(features_to_drop, axis=1)\n",
    "test = test.drop(features_to_drop, axis=1)\n",
    "\n",
    "categorial = train.dtypes[train.dtypes == \"object\"].index\n",
    "numerical = list(set(train.columns) - set(categorial))\n",
    "\n",
    "train = train.replace(np.inf, np.nan)\n",
    "train = train.replace(-np.inf, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffbaa533",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encode, test_encode = encode_cat_feats(train, test, categorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84138f56",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "Обучить алгоритмы LightGBM и XGBoost, получить OOF прогнозы, оценить корреляцию прогнозов на обучающей выборке. Применить модели на тестовую выборку и оценить корреляцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218286eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=1234123, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa723ee",
   "metadata": {},
   "source": [
    "### LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8d6518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 30 22:27:40 2021, Cross-Validation, 110093 rows, 57 cols\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.720913\ttraining's binary_logloss: 0.262911\tvalid_1's auc: 0.702475\tvalid_1's binary_logloss: 0.274015\n",
      "[100]\ttraining's auc: 0.729627\ttraining's binary_logloss: 0.256255\tvalid_1's auc: 0.707372\tvalid_1's binary_logloss: 0.268708\n",
      "[150]\ttraining's auc: 0.736012\ttraining's binary_logloss: 0.252428\tvalid_1's auc: 0.709847\tvalid_1's binary_logloss: 0.266229\n",
      "[200]\ttraining's auc: 0.741844\ttraining's binary_logloss: 0.2499\tvalid_1's auc: 0.712157\tvalid_1's binary_logloss: 0.264895\n",
      "[250]\ttraining's auc: 0.747422\ttraining's binary_logloss: 0.247822\tvalid_1's auc: 0.71508\tvalid_1's binary_logloss: 0.264005\n",
      "[300]\ttraining's auc: 0.752743\ttraining's binary_logloss: 0.246025\tvalid_1's auc: 0.716881\tvalid_1's binary_logloss: 0.263393\n",
      "[350]\ttraining's auc: 0.757574\ttraining's binary_logloss: 0.244463\tvalid_1's auc: 0.718231\tvalid_1's binary_logloss: 0.263041\n",
      "[400]\ttraining's auc: 0.762184\ttraining's binary_logloss: 0.243008\tvalid_1's auc: 0.718909\tvalid_1's binary_logloss: 0.262819\n",
      "[450]\ttraining's auc: 0.766413\ttraining's binary_logloss: 0.241683\tvalid_1's auc: 0.719504\tvalid_1's binary_logloss: 0.262611\n",
      "Early stopping, best iteration is:\n",
      "[439]\ttraining's auc: 0.765603\ttraining's binary_logloss: 0.241971\tvalid_1's auc: 0.719869\tvalid_1's binary_logloss: 0.26264\n",
      "Fold 1, Valid score = 0.71987\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.719572\ttraining's binary_logloss: 0.265944\tvalid_1's auc: 0.712013\tvalid_1's binary_logloss: 0.262549\n",
      "[100]\ttraining's auc: 0.728048\ttraining's binary_logloss: 0.259325\tvalid_1's auc: 0.715478\tvalid_1's binary_logloss: 0.257282\n",
      "[150]\ttraining's auc: 0.734685\ttraining's binary_logloss: 0.255571\tvalid_1's auc: 0.717875\tvalid_1's binary_logloss: 0.254775\n",
      "[200]\ttraining's auc: 0.741366\ttraining's binary_logloss: 0.252942\tvalid_1's auc: 0.719144\tvalid_1's binary_logloss: 0.25339\n",
      "[250]\ttraining's auc: 0.747866\ttraining's binary_logloss: 0.250767\tvalid_1's auc: 0.720325\tvalid_1's binary_logloss: 0.252511\n",
      "[300]\ttraining's auc: 0.753001\ttraining's binary_logloss: 0.248952\tvalid_1's auc: 0.721426\tvalid_1's binary_logloss: 0.251923\n",
      "[350]\ttraining's auc: 0.757624\ttraining's binary_logloss: 0.247355\tvalid_1's auc: 0.722114\tvalid_1's binary_logloss: 0.25158\n",
      "[400]\ttraining's auc: 0.761948\ttraining's binary_logloss: 0.245887\tvalid_1's auc: 0.722505\tvalid_1's binary_logloss: 0.251358\n",
      "Early stopping, best iteration is:\n",
      "[381]\ttraining's auc: 0.760523\ttraining's binary_logloss: 0.246425\tvalid_1's auc: 0.722866\tvalid_1's binary_logloss: 0.251428\n",
      "Fold 2, Valid score = 0.72287\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.71799\ttraining's binary_logloss: 0.265332\tvalid_1's auc: 0.711022\tvalid_1's binary_logloss: 0.265023\n",
      "[100]\ttraining's auc: 0.727153\ttraining's binary_logloss: 0.258776\tvalid_1's auc: 0.718503\tvalid_1's binary_logloss: 0.259372\n",
      "[150]\ttraining's auc: 0.733991\ttraining's binary_logloss: 0.255052\tvalid_1's auc: 0.721353\tvalid_1's binary_logloss: 0.256562\n",
      "[200]\ttraining's auc: 0.739813\ttraining's binary_logloss: 0.252511\tvalid_1's auc: 0.724913\tvalid_1's binary_logloss: 0.254898\n",
      "[250]\ttraining's auc: 0.74564\ttraining's binary_logloss: 0.25046\tvalid_1's auc: 0.727091\tvalid_1's binary_logloss: 0.253777\n",
      "[300]\ttraining's auc: 0.750908\ttraining's binary_logloss: 0.248627\tvalid_1's auc: 0.729148\tvalid_1's binary_logloss: 0.253073\n",
      "[350]\ttraining's auc: 0.755868\ttraining's binary_logloss: 0.24704\tvalid_1's auc: 0.730085\tvalid_1's binary_logloss: 0.252667\n",
      "[400]\ttraining's auc: 0.760403\ttraining's binary_logloss: 0.245589\tvalid_1's auc: 0.730301\tvalid_1's binary_logloss: 0.252391\n",
      "Early stopping, best iteration is:\n",
      "[387]\ttraining's auc: 0.759264\ttraining's binary_logloss: 0.245954\tvalid_1's auc: 0.730482\tvalid_1's binary_logloss: 0.252444\n",
      "Fold 3, Valid score = 0.73048\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.720961\ttraining's binary_logloss: 0.265649\tvalid_1's auc: 0.703622\tvalid_1's binary_logloss: 0.263412\n",
      "[100]\ttraining's auc: 0.72902\ttraining's binary_logloss: 0.259048\tvalid_1's auc: 0.707171\tvalid_1's binary_logloss: 0.258356\n",
      "[150]\ttraining's auc: 0.734828\ttraining's binary_logloss: 0.255361\tvalid_1's auc: 0.709689\tvalid_1's binary_logloss: 0.255966\n",
      "[200]\ttraining's auc: 0.741332\ttraining's binary_logloss: 0.252688\tvalid_1's auc: 0.712945\tvalid_1's binary_logloss: 0.254522\n",
      "[250]\ttraining's auc: 0.746768\ttraining's binary_logloss: 0.250595\tvalid_1's auc: 0.714962\tvalid_1's binary_logloss: 0.253645\n",
      "[300]\ttraining's auc: 0.752423\ttraining's binary_logloss: 0.248788\tvalid_1's auc: 0.716581\tvalid_1's binary_logloss: 0.253036\n",
      "[350]\ttraining's auc: 0.75735\ttraining's binary_logloss: 0.247205\tvalid_1's auc: 0.717987\tvalid_1's binary_logloss: 0.252587\n",
      "[400]\ttraining's auc: 0.761612\ttraining's binary_logloss: 0.245812\tvalid_1's auc: 0.718516\tvalid_1's binary_logloss: 0.252296\n",
      "[450]\ttraining's auc: 0.765484\ttraining's binary_logloss: 0.244523\tvalid_1's auc: 0.71947\tvalid_1's binary_logloss: 0.252124\n",
      "[500]\ttraining's auc: 0.769544\ttraining's binary_logloss: 0.243359\tvalid_1's auc: 0.719815\tvalid_1's binary_logloss: 0.252005\n",
      "[550]\ttraining's auc: 0.773689\ttraining's binary_logloss: 0.242174\tvalid_1's auc: 0.720233\tvalid_1's binary_logloss: 0.251951\n",
      "[600]\ttraining's auc: 0.777251\ttraining's binary_logloss: 0.241067\tvalid_1's auc: 0.720652\tvalid_1's binary_logloss: 0.251828\n",
      "[650]\ttraining's auc: 0.780769\ttraining's binary_logloss: 0.240107\tvalid_1's auc: 0.72073\tvalid_1's binary_logloss: 0.25175\n",
      "Early stopping, best iteration is:\n",
      "[622]\ttraining's auc: 0.778835\ttraining's binary_logloss: 0.240635\tvalid_1's auc: 0.720998\tvalid_1's binary_logloss: 0.251774\n",
      "Fold 4, Valid score = 0.721\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.719631\ttraining's binary_logloss: 0.264597\tvalid_1's auc: 0.704519\tvalid_1's binary_logloss: 0.26797\n",
      "[100]\ttraining's auc: 0.727801\ttraining's binary_logloss: 0.257951\tvalid_1's auc: 0.709363\tvalid_1's binary_logloss: 0.262619\n",
      "[150]\ttraining's auc: 0.734158\ttraining's binary_logloss: 0.254258\tvalid_1's auc: 0.712842\tvalid_1's binary_logloss: 0.260067\n",
      "[200]\ttraining's auc: 0.740642\ttraining's binary_logloss: 0.251686\tvalid_1's auc: 0.715692\tvalid_1's binary_logloss: 0.258663\n",
      "[250]\ttraining's auc: 0.746802\ttraining's binary_logloss: 0.24961\tvalid_1's auc: 0.718268\tvalid_1's binary_logloss: 0.257687\n",
      "[300]\ttraining's auc: 0.751862\ttraining's binary_logloss: 0.247842\tvalid_1's auc: 0.720285\tvalid_1's binary_logloss: 0.257016\n",
      "[350]\ttraining's auc: 0.756334\ttraining's binary_logloss: 0.24625\tvalid_1's auc: 0.721824\tvalid_1's binary_logloss: 0.256513\n",
      "[400]\ttraining's auc: 0.760746\ttraining's binary_logloss: 0.244807\tvalid_1's auc: 0.723427\tvalid_1's binary_logloss: 0.256234\n",
      "[450]\ttraining's auc: 0.764996\ttraining's binary_logloss: 0.243469\tvalid_1's auc: 0.723613\tvalid_1's binary_logloss: 0.256107\n",
      "[500]\ttraining's auc: 0.768947\ttraining's binary_logloss: 0.242275\tvalid_1's auc: 0.724232\tvalid_1's binary_logloss: 0.256086\n",
      "[550]\ttraining's auc: 0.772969\ttraining's binary_logloss: 0.241088\tvalid_1's auc: 0.724438\tvalid_1's binary_logloss: 0.256045\n",
      "[600]\ttraining's auc: 0.776751\ttraining's binary_logloss: 0.239955\tvalid_1's auc: 0.724688\tvalid_1's binary_logloss: 0.256011\n",
      "[650]\ttraining's auc: 0.780564\ttraining's binary_logloss: 0.238865\tvalid_1's auc: 0.724661\tvalid_1's binary_logloss: 0.255991\n",
      "[700]\ttraining's auc: 0.783976\ttraining's binary_logloss: 0.237832\tvalid_1's auc: 0.724998\tvalid_1's binary_logloss: 0.255994\n",
      "Early stopping, best iteration is:\n",
      "[669]\ttraining's auc: 0.781809\ttraining's binary_logloss: 0.238464\tvalid_1's auc: 0.725144\tvalid_1's binary_logloss: 0.255968\n",
      "Fold 5, Valid score = 0.72514\n",
      "Score by each fold: [0.71987, 0.72287, 0.73048, 0.721, 0.72514]\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbm_params = {\n",
    "    \"n_estimators\": 2000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"objective\": \"binary\",\n",
    "    \"boosting_type\": \"gbdt\",    \n",
    "    \"max_bin\": 20,\n",
    "    \"max_depth\": 6,\n",
    "    \"random_seed\": seed\n",
    "}\n",
    "lgbm_fit_params = {\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"verbose\": 50\n",
    "}\n",
    "\n",
    "\n",
    "lgbm_estimators, lgbm_oof_preds = lightgbm_cross_validation(\n",
    "    params=lgbm_params, fit_params=lgbm_fit_params, X=train_encode, y=target, cv=cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33a2615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.72286\n"
     ]
    }
   ],
   "source": [
    "# Score by each fold: [0.71987, 0.72287, 0.73048, 0.721, 0.72514]\n",
    "\n",
    "lgbm_oof_score = roc_auc_score(\n",
    "    target, lgbm_oof_preds\n",
    ")\n",
    "print(f\"OOF-score = {round(lgbm_oof_score, 5)}\")\n",
    "# OOF-score = 0.72286"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44ca28b",
   "metadata": {},
   "source": [
    "### XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc936d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 30 22:28:49 2021, Cross-Validation, 110093 rows, 57 cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.70718\tvalidation_1-auc:0.69074\n",
      "[50]\tvalidation_0-auc:0.72979\tvalidation_1-auc:0.70027\n",
      "[100]\tvalidation_0-auc:0.73670\tvalidation_1-auc:0.70180\n",
      "[150]\tvalidation_0-auc:0.74275\tvalidation_1-auc:0.70298\n",
      "[200]\tvalidation_0-auc:0.75051\tvalidation_1-auc:0.70576\n",
      "[250]\tvalidation_0-auc:0.75551\tvalidation_1-auc:0.70859\n",
      "[300]\tvalidation_0-auc:0.76198\tvalidation_1-auc:0.71080\n",
      "[350]\tvalidation_0-auc:0.76922\tvalidation_1-auc:0.71343\n",
      "[400]\tvalidation_0-auc:0.77623\tvalidation_1-auc:0.71428\n",
      "[450]\tvalidation_0-auc:0.78350\tvalidation_1-auc:0.71605\n",
      "[500]\tvalidation_0-auc:0.79011\tvalidation_1-auc:0.71851\n",
      "[550]\tvalidation_0-auc:0.79577\tvalidation_1-auc:0.72015\n",
      "[600]\tvalidation_0-auc:0.80038\tvalidation_1-auc:0.72054\n",
      "[650]\tvalidation_0-auc:0.80399\tvalidation_1-auc:0.72105\n",
      "[700]\tvalidation_0-auc:0.80760\tvalidation_1-auc:0.72157\n",
      "[750]\tvalidation_0-auc:0.81029\tvalidation_1-auc:0.72216\n",
      "[800]\tvalidation_0-auc:0.81349\tvalidation_1-auc:0.72187\n",
      "[831]\tvalidation_0-auc:0.81494\tvalidation_1-auc:0.72152\n",
      "Fold 1, Valid score = 0.72219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.70677\tvalidation_1-auc:0.69640\n",
      "[50]\tvalidation_0-auc:0.72887\tvalidation_1-auc:0.70707\n",
      "[100]\tvalidation_0-auc:0.73381\tvalidation_1-auc:0.70756\n",
      "[150]\tvalidation_0-auc:0.73873\tvalidation_1-auc:0.71065\n",
      "[200]\tvalidation_0-auc:0.74658\tvalidation_1-auc:0.71351\n",
      "[250]\tvalidation_0-auc:0.75191\tvalidation_1-auc:0.71552\n",
      "[300]\tvalidation_0-auc:0.75979\tvalidation_1-auc:0.71887\n",
      "[350]\tvalidation_0-auc:0.76782\tvalidation_1-auc:0.72167\n",
      "[400]\tvalidation_0-auc:0.77524\tvalidation_1-auc:0.72257\n",
      "[450]\tvalidation_0-auc:0.78238\tvalidation_1-auc:0.72435\n",
      "[500]\tvalidation_0-auc:0.78765\tvalidation_1-auc:0.72590\n",
      "[550]\tvalidation_0-auc:0.79231\tvalidation_1-auc:0.72692\n",
      "[600]\tvalidation_0-auc:0.79712\tvalidation_1-auc:0.72740\n",
      "[638]\tvalidation_0-auc:0.80007\tvalidation_1-auc:0.72739\n",
      "Fold 2, Valid score = 0.72763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.70523\tvalidation_1-auc:0.69588\n",
      "[50]\tvalidation_0-auc:0.72659\tvalidation_1-auc:0.70957\n",
      "[100]\tvalidation_0-auc:0.73378\tvalidation_1-auc:0.71105\n",
      "[150]\tvalidation_0-auc:0.74013\tvalidation_1-auc:0.71264\n",
      "[200]\tvalidation_0-auc:0.74623\tvalidation_1-auc:0.71692\n",
      "[250]\tvalidation_0-auc:0.75292\tvalidation_1-auc:0.72013\n",
      "[300]\tvalidation_0-auc:0.76050\tvalidation_1-auc:0.72339\n",
      "[350]\tvalidation_0-auc:0.76735\tvalidation_1-auc:0.72621\n",
      "[400]\tvalidation_0-auc:0.77428\tvalidation_1-auc:0.72883\n",
      "[450]\tvalidation_0-auc:0.78101\tvalidation_1-auc:0.73109\n",
      "[500]\tvalidation_0-auc:0.78714\tvalidation_1-auc:0.73280\n",
      "[550]\tvalidation_0-auc:0.79260\tvalidation_1-auc:0.73347\n",
      "[600]\tvalidation_0-auc:0.79733\tvalidation_1-auc:0.73467\n",
      "[650]\tvalidation_0-auc:0.80120\tvalidation_1-auc:0.73547\n",
      "[700]\tvalidation_0-auc:0.80431\tvalidation_1-auc:0.73579\n",
      "[739]\tvalidation_0-auc:0.80652\tvalidation_1-auc:0.73610\n",
      "Fold 3, Valid score = 0.73625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.70948\tvalidation_1-auc:0.68769\n",
      "[50]\tvalidation_0-auc:0.72882\tvalidation_1-auc:0.70053\n",
      "[100]\tvalidation_0-auc:0.73365\tvalidation_1-auc:0.70339\n",
      "[150]\tvalidation_0-auc:0.74125\tvalidation_1-auc:0.70610\n",
      "[200]\tvalidation_0-auc:0.74932\tvalidation_1-auc:0.70738\n",
      "[250]\tvalidation_0-auc:0.75545\tvalidation_1-auc:0.70898\n",
      "[300]\tvalidation_0-auc:0.76028\tvalidation_1-auc:0.71193\n",
      "[350]\tvalidation_0-auc:0.76748\tvalidation_1-auc:0.71460\n",
      "[400]\tvalidation_0-auc:0.77399\tvalidation_1-auc:0.71734\n",
      "[450]\tvalidation_0-auc:0.78144\tvalidation_1-auc:0.71884\n",
      "[500]\tvalidation_0-auc:0.78752\tvalidation_1-auc:0.71982\n",
      "[550]\tvalidation_0-auc:0.79309\tvalidation_1-auc:0.72135\n",
      "[600]\tvalidation_0-auc:0.79779\tvalidation_1-auc:0.72213\n",
      "[650]\tvalidation_0-auc:0.80115\tvalidation_1-auc:0.72293\n",
      "[700]\tvalidation_0-auc:0.80414\tvalidation_1-auc:0.72341\n",
      "[750]\tvalidation_0-auc:0.80684\tvalidation_1-auc:0.72375\n",
      "[800]\tvalidation_0-auc:0.80906\tvalidation_1-auc:0.72414\n",
      "[850]\tvalidation_0-auc:0.81148\tvalidation_1-auc:0.72449\n",
      "[900]\tvalidation_0-auc:0.81404\tvalidation_1-auc:0.72485\n",
      "[950]\tvalidation_0-auc:0.81648\tvalidation_1-auc:0.72517\n",
      "[1000]\tvalidation_0-auc:0.81857\tvalidation_1-auc:0.72534\n",
      "[1050]\tvalidation_0-auc:0.82046\tvalidation_1-auc:0.72503\n",
      "[1057]\tvalidation_0-auc:0.82083\tvalidation_1-auc:0.72500\n",
      "Fold 4, Valid score = 0.7254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.70842\tvalidation_1-auc:0.69386\n",
      "[50]\tvalidation_0-auc:0.72713\tvalidation_1-auc:0.70053\n",
      "[100]\tvalidation_0-auc:0.73517\tvalidation_1-auc:0.70244\n",
      "[150]\tvalidation_0-auc:0.73988\tvalidation_1-auc:0.70425\n",
      "[200]\tvalidation_0-auc:0.74681\tvalidation_1-auc:0.70972\n",
      "[250]\tvalidation_0-auc:0.75297\tvalidation_1-auc:0.71228\n",
      "[300]\tvalidation_0-auc:0.75939\tvalidation_1-auc:0.71458\n",
      "[350]\tvalidation_0-auc:0.76757\tvalidation_1-auc:0.71674\n",
      "[400]\tvalidation_0-auc:0.77517\tvalidation_1-auc:0.71874\n",
      "[450]\tvalidation_0-auc:0.78240\tvalidation_1-auc:0.72130\n",
      "[500]\tvalidation_0-auc:0.78817\tvalidation_1-auc:0.72325\n",
      "[550]\tvalidation_0-auc:0.79380\tvalidation_1-auc:0.72477\n",
      "[600]\tvalidation_0-auc:0.79852\tvalidation_1-auc:0.72533\n",
      "[650]\tvalidation_0-auc:0.80200\tvalidation_1-auc:0.72573\n",
      "[700]\tvalidation_0-auc:0.80489\tvalidation_1-auc:0.72655\n",
      "[750]\tvalidation_0-auc:0.80787\tvalidation_1-auc:0.72698\n",
      "[789]\tvalidation_0-auc:0.81006\tvalidation_1-auc:0.72693\n",
      "Fold 5, Valid score = 0.72702\n",
      "Score by each fold: [0.72219, 0.72763, 0.73625, 0.7254, 0.72702]\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    \"n_estimators\": 2000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"max_bin\": 20,\n",
    "    \"max_depth\": 6,\n",
    "    \"nthread\": 6,\n",
    "    \"seed\": seed\n",
    "}\n",
    "xgb_fit_params = {\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"verbose\":50,    \n",
    "    \"eval_metric\": \"auc\"    \n",
    "}\n",
    "\n",
    "xgb_estimators, xgb_oof_preds = xgboost_cross_validation(\n",
    "    params=xgb_params, fit_params=xgb_fit_params, X=train_encode, y=target, cv=cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bcd16cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.72668\n"
     ]
    }
   ],
   "source": [
    "# Score by each fold: [0.72219, 0.72763, 0.73625, 0.7254, 0.72702]\n",
    "\n",
    "xgb_oof_score = roc_auc_score(\n",
    "    target, xgb_oof_preds\n",
    ")\n",
    "print(f\"OOF-score = {round(xgb_oof_score, 5)}\")\n",
    "# OOF-score = 0.72668"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c0553",
   "metadata": {},
   "source": [
    "### Prediction Correlation for LightGBM & XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "122d403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-2808fd249174>:7: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask = np.zeros_like(corr_2, dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "scores_2 = pd.DataFrame({\n",
    "    \"lgbm\": lgbm_oof_preds,\n",
    "    \"xgb\": xgb_oof_preds,\n",
    "})\n",
    "\n",
    "corr_2 = scores_2.corr()\n",
    "mask = np.zeros_like(corr_2, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c9d69ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 8))\n",
    "sns.heatmap(corr_2, mask=mask, annot=True, fmt=\".4g\", square=True, cmap=\"viridis\", ax=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8f901",
   "metadata": {},
   "source": [
    "### Test Correlation for LightGBM & XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a47a6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_estimators(test, estimators, test_id=test_id):\n",
    "    y_pred = np.zeros(test.shape[0])\n",
    "\n",
    "    for estimator in estimators:\n",
    "        y_pred += estimator.predict_proba(test)[:, 1]\n",
    "        \n",
    "    y_pred = pd.DataFrame({\n",
    "        \"APPLICATION_NUMBER\": test_id,\n",
    "        \"TARGET\": y_pred / len(estimators)\n",
    "    })\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaf34f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_preds = predict_by_estimators(test_encode, xgb_estimators)\n",
    "lgbm_test_preds = predict_by_estimators(test_encode, lgbm_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9198154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-d56a9182218a>:7: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask = np.zeros_like(corr_test_2, dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "scores_test_2 = pd.DataFrame({\n",
    "    \"lgbm\": lgbm_test_preds[\"TARGET\"],\n",
    "    \"xgb\": xgb_test_preds[\"TARGET\"],\n",
    "})\n",
    "\n",
    "corr_test_2 = scores_test_2.corr()\n",
    "mask = np.zeros_like(corr_test_2, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00dce61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 8))\n",
    "sns.heatmap(corr_test_2, mask=mask, annot=True, fmt=\".4g\", square=True, cmap=\"viridis\", ax=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2cfb4",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "* Наблюдается высокая коррелляция между рассматриваемыми моделями LightGBM и XGBoost, что свидетельствует о схожей предсказательной силе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42f6ac",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "Усреднить прогнозы с помощью арифмитического среднего, геометрического среднего и усреднить ранги, сделать выводы о качестве отдельных моделей и о качестве комбинации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b008fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMean Score = 0.72584\n",
      "GMean Score = 0.72576\n",
      "Rankdata Score = 0.72584\n",
      "GMean Rankdata Score = 0.72582\n"
     ]
    }
   ],
   "source": [
    "scores_amean = scores_2.mean(axis=1)\n",
    "auc_amean = roc_auc_score(target, scores_amean)\n",
    "print(f\"AMean Score = {round(auc_amean, 5)}\")\n",
    "\n",
    "scores_gmean = gmean(scores_2, axis=1)\n",
    "auc_gmean = roc_auc_score(target, scores_gmean)\n",
    "print(f\"GMean Score = {round(auc_gmean, 5)}\")\n",
    "\n",
    "scores_rankdata = scores_2.rank().mean(axis=1)\n",
    "auc_rankdata = roc_auc_score(target, scores_rankdata)\n",
    "print(f\"Rankdata Score = {round(auc_rankdata, 5)}\")\n",
    "\n",
    "scores_gmean_rankdata = gmean(scores_2.rank(), axis=1)\n",
    "auc_gmean_rankdata = roc_auc_score(target, scores_gmean_rankdata)\n",
    "print(f\"GMean Rankdata Score = {round(auc_gmean_rankdata, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5e41a",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "* Качество на одиночных моделях составляет: LightGBM - 0.72286, XGBoost - 0.72668\n",
    "* Качество усредненных прогнозов по двум моделям состаявляет AMean - 0.72584, GMean - 0.72576, Rankdata - 0.72584, GMean Rankdata - 0.72582 .\n",
    "* Качество усредненных прогнозов по двум моделям близко друг к другу. \n",
    "* Качество на одиночной модели XGBoost выше, чем качество усредненных прогнозов по двум моделям и качество на одиночной модели LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea13c44a",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "Обучить CatBoost, получить OOF прогнозы и выполнить задание 1 для трех моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057754e3",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "178b1c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 30 23:01:08 2021, Cross-Validation, 110093 rows, 57 cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6676419\ttest1: 0.6565851\tbest: 0.6565851 (0)\ttotal: 65ms\tremaining: 2m 9s\n",
      "10:\ttest: 0.7005791\ttest1: 0.6931642\tbest: 0.6931642 (10)\ttotal: 773ms\tremaining: 2m 19s\n",
      "20:\ttest: 0.7025649\ttest1: 0.6953875\tbest: 0.6962007 (14)\ttotal: 1.49s\tremaining: 2m 20s\n",
      "30:\ttest: 0.7049967\ttest1: 0.6972281\tbest: 0.6976513 (29)\ttotal: 2.11s\tremaining: 2m 13s\n",
      "40:\ttest: 0.7059253\ttest1: 0.6975699\tbest: 0.6981486 (34)\ttotal: 2.76s\tremaining: 2m 11s\n",
      "50:\ttest: 0.7072350\ttest1: 0.6990368\tbest: 0.6990368 (50)\ttotal: 3.41s\tremaining: 2m 10s\n",
      "60:\ttest: 0.7073784\ttest1: 0.6988423\tbest: 0.6995232 (56)\ttotal: 4s\tremaining: 2m 7s\n",
      "70:\ttest: 0.7082965\ttest1: 0.7002004\tbest: 0.7002004 (70)\ttotal: 4.7s\tremaining: 2m 7s\n",
      "80:\ttest: 0.7087690\ttest1: 0.7010764\tbest: 0.7013132 (79)\ttotal: 5.34s\tremaining: 2m 6s\n",
      "90:\ttest: 0.7099838\ttest1: 0.7022448\tbest: 0.7024455 (89)\ttotal: 5.98s\tremaining: 2m 5s\n",
      "100:\ttest: 0.7109242\ttest1: 0.7032906\tbest: 0.7032906 (100)\ttotal: 6.68s\tremaining: 2m 5s\n",
      "110:\ttest: 0.7112247\ttest1: 0.7038740\tbest: 0.7039193 (105)\ttotal: 7.34s\tremaining: 2m 5s\n",
      "120:\ttest: 0.7118179\ttest1: 0.7045740\tbest: 0.7045740 (120)\ttotal: 7.89s\tremaining: 2m 2s\n",
      "130:\ttest: 0.7123298\ttest1: 0.7051367\tbest: 0.7051367 (130)\ttotal: 8.46s\tremaining: 2m\n",
      "140:\ttest: 0.7133194\ttest1: 0.7059791\tbest: 0.7059791 (140)\ttotal: 9.03s\tremaining: 1m 59s\n",
      "150:\ttest: 0.7137146\ttest1: 0.7061418\tbest: 0.7061418 (150)\ttotal: 9.6s\tremaining: 1m 57s\n",
      "160:\ttest: 0.7142294\ttest1: 0.7064718\tbest: 0.7065218 (158)\ttotal: 10.2s\tremaining: 1m 56s\n",
      "170:\ttest: 0.7146912\ttest1: 0.7068182\tbest: 0.7068182 (170)\ttotal: 10.9s\tremaining: 1m 56s\n",
      "180:\ttest: 0.7153592\ttest1: 0.7069812\tbest: 0.7070330 (178)\ttotal: 11.5s\tremaining: 1m 55s\n",
      "190:\ttest: 0.7161215\ttest1: 0.7074588\tbest: 0.7077232 (187)\ttotal: 12.1s\tremaining: 1m 54s\n",
      "200:\ttest: 0.7171668\ttest1: 0.7086127\tbest: 0.7086127 (200)\ttotal: 12.8s\tremaining: 1m 54s\n",
      "210:\ttest: 0.7173632\ttest1: 0.7090861\tbest: 0.7091726 (208)\ttotal: 13.4s\tremaining: 1m 53s\n",
      "220:\ttest: 0.7180694\ttest1: 0.7095296\tbest: 0.7095854 (218)\ttotal: 13.9s\tremaining: 1m 52s\n",
      "230:\ttest: 0.7186273\ttest1: 0.7099579\tbest: 0.7099579 (230)\ttotal: 14.5s\tremaining: 1m 51s\n",
      "240:\ttest: 0.7192101\ttest1: 0.7103842\tbest: 0.7104699 (239)\ttotal: 15.1s\tremaining: 1m 50s\n",
      "250:\ttest: 0.7195405\ttest1: 0.7108951\tbest: 0.7109810 (249)\ttotal: 15.8s\tremaining: 1m 50s\n",
      "260:\ttest: 0.7203921\ttest1: 0.7113517\tbest: 0.7113517 (260)\ttotal: 16.5s\tremaining: 1m 50s\n",
      "270:\ttest: 0.7209444\ttest1: 0.7117957\tbest: 0.7117957 (270)\ttotal: 17.2s\tremaining: 1m 49s\n",
      "280:\ttest: 0.7214426\ttest1: 0.7122185\tbest: 0.7122201 (278)\ttotal: 17.9s\tremaining: 1m 49s\n",
      "290:\ttest: 0.7218668\ttest1: 0.7128340\tbest: 0.7130180 (289)\ttotal: 18.6s\tremaining: 1m 49s\n",
      "300:\ttest: 0.7223988\ttest1: 0.7131276\tbest: 0.7131610 (298)\ttotal: 19.2s\tremaining: 1m 48s\n",
      "310:\ttest: 0.7229288\ttest1: 0.7136353\tbest: 0.7136588 (309)\ttotal: 19.8s\tremaining: 1m 47s\n",
      "320:\ttest: 0.7235007\ttest1: 0.7137309\tbest: 0.7138578 (318)\ttotal: 20.4s\tremaining: 1m 46s\n",
      "330:\ttest: 0.7239122\ttest1: 0.7138641\tbest: 0.7139734 (324)\ttotal: 21s\tremaining: 1m 46s\n",
      "340:\ttest: 0.7245925\ttest1: 0.7137225\tbest: 0.7139734 (324)\ttotal: 21.7s\tremaining: 1m 45s\n",
      "350:\ttest: 0.7249552\ttest1: 0.7140680\tbest: 0.7140680 (350)\ttotal: 22.3s\tremaining: 1m 44s\n",
      "360:\ttest: 0.7254940\ttest1: 0.7142934\tbest: 0.7144344 (358)\ttotal: 22.9s\tremaining: 1m 44s\n",
      "370:\ttest: 0.7261752\ttest1: 0.7146796\tbest: 0.7146796 (370)\ttotal: 23.6s\tremaining: 1m 43s\n",
      "380:\ttest: 0.7265299\ttest1: 0.7146401\tbest: 0.7146796 (370)\ttotal: 24.2s\tremaining: 1m 42s\n",
      "390:\ttest: 0.7271171\ttest1: 0.7150175\tbest: 0.7150849 (388)\ttotal: 24.8s\tremaining: 1m 42s\n",
      "400:\ttest: 0.7276370\ttest1: 0.7153257\tbest: 0.7153257 (400)\ttotal: 25.4s\tremaining: 1m 41s\n",
      "410:\ttest: 0.7280321\ttest1: 0.7158516\tbest: 0.7158516 (410)\ttotal: 25.9s\tremaining: 1m 40s\n",
      "420:\ttest: 0.7284742\ttest1: 0.7164070\tbest: 0.7164726 (419)\ttotal: 26.5s\tremaining: 1m 39s\n",
      "430:\ttest: 0.7288658\ttest1: 0.7163910\tbest: 0.7165275 (421)\ttotal: 27.1s\tremaining: 1m 38s\n",
      "440:\ttest: 0.7293934\ttest1: 0.7165056\tbest: 0.7166820 (433)\ttotal: 27.7s\tremaining: 1m 38s\n",
      "450:\ttest: 0.7297042\ttest1: 0.7165595\tbest: 0.7166820 (433)\ttotal: 28.3s\tremaining: 1m 37s\n",
      "460:\ttest: 0.7300243\ttest1: 0.7168087\tbest: 0.7168087 (460)\ttotal: 28.9s\tremaining: 1m 36s\n",
      "470:\ttest: 0.7304521\ttest1: 0.7172189\tbest: 0.7172466 (467)\ttotal: 29.6s\tremaining: 1m 36s\n",
      "480:\ttest: 0.7309273\ttest1: 0.7171468\tbest: 0.7172484 (472)\ttotal: 30.2s\tremaining: 1m 35s\n",
      "490:\ttest: 0.7313342\ttest1: 0.7172284\tbest: 0.7173312 (487)\ttotal: 30.8s\tremaining: 1m 34s\n",
      "500:\ttest: 0.7315794\ttest1: 0.7174997\tbest: 0.7174997 (500)\ttotal: 31.3s\tremaining: 1m 33s\n",
      "510:\ttest: 0.7319490\ttest1: 0.7176725\tbest: 0.7177151 (505)\ttotal: 31.9s\tremaining: 1m 32s\n",
      "520:\ttest: 0.7324291\ttest1: 0.7177675\tbest: 0.7177967 (519)\ttotal: 32.5s\tremaining: 1m 32s\n",
      "530:\ttest: 0.7328310\ttest1: 0.7180912\tbest: 0.7181414 (529)\ttotal: 33.1s\tremaining: 1m 31s\n",
      "540:\ttest: 0.7332295\ttest1: 0.7181685\tbest: 0.7181773 (539)\ttotal: 33.7s\tremaining: 1m 30s\n",
      "550:\ttest: 0.7335080\ttest1: 0.7183016\tbest: 0.7183037 (549)\ttotal: 34.3s\tremaining: 1m 30s\n",
      "560:\ttest: 0.7338149\ttest1: 0.7185819\tbest: 0.7185819 (560)\ttotal: 34.9s\tremaining: 1m 29s\n",
      "570:\ttest: 0.7342884\ttest1: 0.7186826\tbest: 0.7187102 (569)\ttotal: 35.6s\tremaining: 1m 29s\n",
      "580:\ttest: 0.7346191\ttest1: 0.7187392\tbest: 0.7187964 (578)\ttotal: 36.1s\tremaining: 1m 28s\n",
      "590:\ttest: 0.7350471\ttest1: 0.7187842\tbest: 0.7188735 (581)\ttotal: 36.7s\tremaining: 1m 27s\n",
      "600:\ttest: 0.7353294\ttest1: 0.7189256\tbest: 0.7189256 (600)\ttotal: 37.3s\tremaining: 1m 26s\n",
      "610:\ttest: 0.7356591\ttest1: 0.7188709\tbest: 0.7189635 (606)\ttotal: 37.8s\tremaining: 1m 26s\n",
      "620:\ttest: 0.7359690\ttest1: 0.7188777\tbest: 0.7189635 (606)\ttotal: 38.5s\tremaining: 1m 25s\n",
      "630:\ttest: 0.7362757\ttest1: 0.7190210\tbest: 0.7190210 (630)\ttotal: 39.1s\tremaining: 1m 24s\n",
      "640:\ttest: 0.7367948\ttest1: 0.7193572\tbest: 0.7193596 (639)\ttotal: 39.6s\tremaining: 1m 24s\n",
      "650:\ttest: 0.7371009\ttest1: 0.7193045\tbest: 0.7193596 (639)\ttotal: 40.3s\tremaining: 1m 23s\n",
      "660:\ttest: 0.7374589\ttest1: 0.7194241\tbest: 0.7195356 (653)\ttotal: 40.9s\tremaining: 1m 22s\n",
      "670:\ttest: 0.7377961\ttest1: 0.7194359\tbest: 0.7195448 (667)\ttotal: 41.5s\tremaining: 1m 22s\n",
      "680:\ttest: 0.7382540\ttest1: 0.7195416\tbest: 0.7195448 (667)\ttotal: 42.1s\tremaining: 1m 21s\n",
      "690:\ttest: 0.7385708\ttest1: 0.7197250\tbest: 0.7197250 (690)\ttotal: 42.7s\tremaining: 1m 20s\n",
      "700:\ttest: 0.7388226\ttest1: 0.7197125\tbest: 0.7197250 (690)\ttotal: 43.2s\tremaining: 1m 20s\n",
      "710:\ttest: 0.7391269\ttest1: 0.7198464\tbest: 0.7198464 (710)\ttotal: 43.8s\tremaining: 1m 19s\n",
      "720:\ttest: 0.7394422\ttest1: 0.7198327\tbest: 0.7198574 (719)\ttotal: 44.4s\tremaining: 1m 18s\n",
      "730:\ttest: 0.7396940\ttest1: 0.7199933\tbest: 0.7200411 (726)\ttotal: 45s\tremaining: 1m 18s\n",
      "740:\ttest: 0.7399627\ttest1: 0.7199993\tbest: 0.7200411 (726)\ttotal: 45.6s\tremaining: 1m 17s\n",
      "750:\ttest: 0.7402787\ttest1: 0.7202773\tbest: 0.7202773 (750)\ttotal: 46.3s\tremaining: 1m 16s\n",
      "760:\ttest: 0.7405666\ttest1: 0.7201620\tbest: 0.7202773 (750)\ttotal: 46.9s\tremaining: 1m 16s\n",
      "770:\ttest: 0.7408364\ttest1: 0.7201813\tbest: 0.7202773 (750)\ttotal: 47.4s\tremaining: 1m 15s\n",
      "780:\ttest: 0.7410880\ttest1: 0.7204761\tbest: 0.7204761 (780)\ttotal: 48s\tremaining: 1m 14s\n",
      "790:\ttest: 0.7413100\ttest1: 0.7202721\tbest: 0.7204828 (786)\ttotal: 48.6s\tremaining: 1m 14s\n",
      "800:\ttest: 0.7416199\ttest1: 0.7205861\tbest: 0.7207299 (797)\ttotal: 49.2s\tremaining: 1m 13s\n",
      "810:\ttest: 0.7419163\ttest1: 0.7208805\tbest: 0.7208805 (810)\ttotal: 49.8s\tremaining: 1m 13s\n",
      "820:\ttest: 0.7421868\ttest1: 0.7209919\tbest: 0.7209920 (819)\ttotal: 50.4s\tremaining: 1m 12s\n",
      "830:\ttest: 0.7424230\ttest1: 0.7210396\tbest: 0.7210941 (824)\ttotal: 51s\tremaining: 1m 11s\n",
      "840:\ttest: 0.7426228\ttest1: 0.7211955\tbest: 0.7211955 (840)\ttotal: 51.6s\tremaining: 1m 11s\n",
      "850:\ttest: 0.7428975\ttest1: 0.7211692\tbest: 0.7212992 (844)\ttotal: 52.3s\tremaining: 1m 10s\n",
      "860:\ttest: 0.7432303\ttest1: 0.7212736\tbest: 0.7212992 (844)\ttotal: 52.8s\tremaining: 1m 9s\n",
      "870:\ttest: 0.7435020\ttest1: 0.7213149\tbest: 0.7214822 (866)\ttotal: 53.4s\tremaining: 1m 9s\n",
      "880:\ttest: 0.7437941\ttest1: 0.7215349\tbest: 0.7215447 (878)\ttotal: 54s\tremaining: 1m 8s\n",
      "890:\ttest: 0.7440177\ttest1: 0.7215830\tbest: 0.7216454 (887)\ttotal: 54.6s\tremaining: 1m 7s\n",
      "900:\ttest: 0.7443140\ttest1: 0.7215472\tbest: 0.7216965 (893)\ttotal: 55.2s\tremaining: 1m 7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910:\ttest: 0.7445251\ttest1: 0.7215666\tbest: 0.7216965 (893)\ttotal: 55.8s\tremaining: 1m 6s\n",
      "920:\ttest: 0.7449449\ttest1: 0.7216079\tbest: 0.7216965 (893)\ttotal: 56.3s\tremaining: 1m 6s\n",
      "930:\ttest: 0.7452712\ttest1: 0.7215612\tbest: 0.7216965 (893)\ttotal: 57s\tremaining: 1m 5s\n",
      "940:\ttest: 0.7456011\ttest1: 0.7217527\tbest: 0.7217527 (940)\ttotal: 57.6s\tremaining: 1m 4s\n",
      "950:\ttest: 0.7458586\ttest1: 0.7216341\tbest: 0.7217527 (940)\ttotal: 58.2s\tremaining: 1m 4s\n",
      "960:\ttest: 0.7460429\ttest1: 0.7217038\tbest: 0.7217527 (940)\ttotal: 58.8s\tremaining: 1m 3s\n",
      "970:\ttest: 0.7464212\ttest1: 0.7217419\tbest: 0.7218205 (963)\ttotal: 59.3s\tremaining: 1m 2s\n",
      "980:\ttest: 0.7465616\ttest1: 0.7218198\tbest: 0.7218205 (963)\ttotal: 59.9s\tremaining: 1m 2s\n",
      "990:\ttest: 0.7468043\ttest1: 0.7218344\tbest: 0.7218420 (989)\ttotal: 1m\tremaining: 1m 1s\n",
      "1000:\ttest: 0.7470626\ttest1: 0.7217553\tbest: 0.7218420 (989)\ttotal: 1m 1s\tremaining: 1m 1s\n",
      "1010:\ttest: 0.7472961\ttest1: 0.7217800\tbest: 0.7218420 (989)\ttotal: 1m 1s\tremaining: 1m\n",
      "1020:\ttest: 0.7475988\ttest1: 0.7218083\tbest: 0.7218420 (989)\ttotal: 1m 2s\tremaining: 59.7s\n",
      "1030:\ttest: 0.7478446\ttest1: 0.7217981\tbest: 0.7218420 (989)\ttotal: 1m 2s\tremaining: 59.2s\n",
      "1040:\ttest: 0.7481670\ttest1: 0.7219261\tbest: 0.7219456 (1039)\ttotal: 1m 3s\tremaining: 58.6s\n",
      "1050:\ttest: 0.7485303\ttest1: 0.7219530\tbest: 0.7219532 (1042)\ttotal: 1m 4s\tremaining: 57.9s\n",
      "1060:\ttest: 0.7487438\ttest1: 0.7220021\tbest: 0.7220502 (1055)\ttotal: 1m 4s\tremaining: 57.3s\n",
      "1070:\ttest: 0.7489527\ttest1: 0.7221706\tbest: 0.7221706 (1070)\ttotal: 1m 5s\tremaining: 56.6s\n",
      "1080:\ttest: 0.7492248\ttest1: 0.7223264\tbest: 0.7223422 (1077)\ttotal: 1m 5s\tremaining: 56s\n",
      "1090:\ttest: 0.7495744\ttest1: 0.7223575\tbest: 0.7223889 (1088)\ttotal: 1m 6s\tremaining: 55.3s\n",
      "1100:\ttest: 0.7498900\ttest1: 0.7224538\tbest: 0.7224775 (1093)\ttotal: 1m 7s\tremaining: 54.7s\n",
      "1110:\ttest: 0.7500786\ttest1: 0.7224830\tbest: 0.7224970 (1104)\ttotal: 1m 7s\tremaining: 54.1s\n",
      "1120:\ttest: 0.7503456\ttest1: 0.7224632\tbest: 0.7224976 (1112)\ttotal: 1m 8s\tremaining: 53.5s\n",
      "1130:\ttest: 0.7506213\ttest1: 0.7225111\tbest: 0.7225453 (1128)\ttotal: 1m 8s\tremaining: 52.9s\n",
      "1140:\ttest: 0.7508797\ttest1: 0.7225399\tbest: 0.7225880 (1137)\ttotal: 1m 9s\tremaining: 52.3s\n",
      "1150:\ttest: 0.7511026\ttest1: 0.7224743\tbest: 0.7226108 (1145)\ttotal: 1m 10s\tremaining: 51.7s\n",
      "1160:\ttest: 0.7513953\ttest1: 0.7225396\tbest: 0.7226108 (1145)\ttotal: 1m 10s\tremaining: 51.1s\n",
      "1170:\ttest: 0.7517152\ttest1: 0.7226706\tbest: 0.7226706 (1170)\ttotal: 1m 11s\tremaining: 50.4s\n",
      "1180:\ttest: 0.7521466\ttest1: 0.7224444\tbest: 0.7226748 (1171)\ttotal: 1m 11s\tremaining: 49.8s\n",
      "1190:\ttest: 0.7524026\ttest1: 0.7225737\tbest: 0.7226748 (1171)\ttotal: 1m 12s\tremaining: 49.2s\n",
      "1200:\ttest: 0.7525932\ttest1: 0.7225506\tbest: 0.7226748 (1171)\ttotal: 1m 13s\tremaining: 48.6s\n",
      "1210:\ttest: 0.7528621\ttest1: 0.7226819\tbest: 0.7227819 (1203)\ttotal: 1m 13s\tremaining: 48s\n",
      "1220:\ttest: 0.7530343\ttest1: 0.7227127\tbest: 0.7228052 (1219)\ttotal: 1m 14s\tremaining: 47.4s\n",
      "1230:\ttest: 0.7532546\ttest1: 0.7227717\tbest: 0.7228194 (1224)\ttotal: 1m 14s\tremaining: 46.8s\n",
      "1240:\ttest: 0.7535939\ttest1: 0.7227838\tbest: 0.7228194 (1224)\ttotal: 1m 15s\tremaining: 46.1s\n",
      "1250:\ttest: 0.7538531\ttest1: 0.7228695\tbest: 0.7228816 (1247)\ttotal: 1m 15s\tremaining: 45.5s\n",
      "1260:\ttest: 0.7540639\ttest1: 0.7228975\tbest: 0.7229149 (1259)\ttotal: 1m 16s\tremaining: 44.9s\n",
      "1270:\ttest: 0.7542879\ttest1: 0.7229354\tbest: 0.7229522 (1267)\ttotal: 1m 17s\tremaining: 44.2s\n",
      "1280:\ttest: 0.7545900\ttest1: 0.7230928\tbest: 0.7230928 (1280)\ttotal: 1m 17s\tremaining: 43.6s\n",
      "1290:\ttest: 0.7548927\ttest1: 0.7229262\tbest: 0.7231149 (1284)\ttotal: 1m 18s\tremaining: 43s\n",
      "1300:\ttest: 0.7552124\ttest1: 0.7229515\tbest: 0.7231149 (1284)\ttotal: 1m 18s\tremaining: 42.4s\n",
      "1310:\ttest: 0.7554714\ttest1: 0.7230580\tbest: 0.7231149 (1284)\ttotal: 1m 19s\tremaining: 41.8s\n",
      "1320:\ttest: 0.7556427\ttest1: 0.7230278\tbest: 0.7231149 (1284)\ttotal: 1m 20s\tremaining: 41.2s\n",
      "1330:\ttest: 0.7558581\ttest1: 0.7229656\tbest: 0.7231149 (1284)\ttotal: 1m 20s\tremaining: 40.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7231149346\n",
      "bestIteration = 1284\n",
      "\n",
      "Shrink model to first 1285 iterations.\n",
      "Fold 1, Valid score = 0.72311\n",
      "0:\ttest: 0.6671790\ttest1: 0.6688976\tbest: 0.6688976 (0)\ttotal: 70.1ms\tremaining: 2m 20s\n",
      "10:\ttest: 0.6993743\ttest1: 0.6994996\tbest: 0.6998857 (9)\ttotal: 596ms\tremaining: 1m 47s\n",
      "20:\ttest: 0.7021329\ttest1: 0.7020301\tbest: 0.7027029 (19)\ttotal: 1.18s\tremaining: 1m 51s\n",
      "30:\ttest: 0.7049353\ttest1: 0.7045550\tbest: 0.7045550 (30)\ttotal: 1.77s\tremaining: 1m 52s\n",
      "40:\ttest: 0.7059904\ttest1: 0.7059350\tbest: 0.7059350 (40)\ttotal: 2.38s\tremaining: 1m 53s\n",
      "50:\ttest: 0.7069443\ttest1: 0.7066711\tbest: 0.7068792 (45)\ttotal: 2.93s\tremaining: 1m 52s\n",
      "60:\ttest: 0.7073963\ttest1: 0.7071814\tbest: 0.7071814 (60)\ttotal: 3.54s\tremaining: 1m 52s\n",
      "70:\ttest: 0.7080923\ttest1: 0.7077126\tbest: 0.7083703 (66)\ttotal: 4.15s\tremaining: 1m 52s\n",
      "80:\ttest: 0.7086463\ttest1: 0.7085221\tbest: 0.7085221 (80)\ttotal: 4.7s\tremaining: 1m 51s\n",
      "90:\ttest: 0.7090024\ttest1: 0.7087957\tbest: 0.7087957 (90)\ttotal: 5.28s\tremaining: 1m 50s\n",
      "100:\ttest: 0.7097516\ttest1: 0.7089333\tbest: 0.7089333 (100)\ttotal: 5.78s\tremaining: 1m 48s\n",
      "110:\ttest: 0.7103428\ttest1: 0.7093748\tbest: 0.7096025 (105)\ttotal: 6.32s\tremaining: 1m 47s\n",
      "120:\ttest: 0.7109495\ttest1: 0.7098904\tbest: 0.7098904 (120)\ttotal: 6.86s\tremaining: 1m 46s\n",
      "130:\ttest: 0.7116583\ttest1: 0.7101262\tbest: 0.7101262 (130)\ttotal: 7.44s\tremaining: 1m 46s\n",
      "140:\ttest: 0.7122907\ttest1: 0.7104017\tbest: 0.7104075 (139)\ttotal: 8.02s\tremaining: 1m 45s\n",
      "150:\ttest: 0.7125393\ttest1: 0.7109680\tbest: 0.7109942 (147)\ttotal: 8.58s\tremaining: 1m 45s\n",
      "160:\ttest: 0.7129327\ttest1: 0.7113181\tbest: 0.7113181 (160)\ttotal: 9.16s\tremaining: 1m 44s\n",
      "170:\ttest: 0.7135400\ttest1: 0.7120427\tbest: 0.7123102 (168)\ttotal: 9.75s\tremaining: 1m 44s\n",
      "180:\ttest: 0.7141540\ttest1: 0.7125898\tbest: 0.7125898 (180)\ttotal: 10.3s\tremaining: 1m 43s\n",
      "190:\ttest: 0.7143455\ttest1: 0.7129797\tbest: 0.7129944 (187)\ttotal: 10.9s\tremaining: 1m 43s\n",
      "200:\ttest: 0.7153203\ttest1: 0.7142545\tbest: 0.7142970 (199)\ttotal: 11.4s\tremaining: 1m 42s\n",
      "210:\ttest: 0.7157546\ttest1: 0.7147498\tbest: 0.7149589 (209)\ttotal: 12s\tremaining: 1m 41s\n",
      "220:\ttest: 0.7164302\ttest1: 0.7157921\tbest: 0.7157921 (220)\ttotal: 12.5s\tremaining: 1m 40s\n",
      "230:\ttest: 0.7170514\ttest1: 0.7161125\tbest: 0.7161125 (230)\ttotal: 13.1s\tremaining: 1m 40s\n",
      "240:\ttest: 0.7176777\ttest1: 0.7161877\tbest: 0.7162940 (238)\ttotal: 13.7s\tremaining: 1m 40s\n",
      "250:\ttest: 0.7183955\ttest1: 0.7166267\tbest: 0.7167530 (244)\ttotal: 14.3s\tremaining: 1m 39s\n",
      "260:\ttest: 0.7188387\ttest1: 0.7168093\tbest: 0.7169787 (256)\ttotal: 14.9s\tremaining: 1m 39s\n",
      "270:\ttest: 0.7193522\ttest1: 0.7170779\tbest: 0.7170789 (269)\ttotal: 15.5s\tremaining: 1m 38s\n",
      "280:\ttest: 0.7203171\ttest1: 0.7176228\tbest: 0.7176570 (278)\ttotal: 16s\tremaining: 1m 38s\n",
      "290:\ttest: 0.7210470\ttest1: 0.7181567\tbest: 0.7181567 (290)\ttotal: 16.6s\tremaining: 1m 37s\n",
      "300:\ttest: 0.7214723\ttest1: 0.7180843\tbest: 0.7181567 (290)\ttotal: 17.2s\tremaining: 1m 36s\n",
      "310:\ttest: 0.7219754\ttest1: 0.7181846\tbest: 0.7182732 (308)\ttotal: 17.7s\tremaining: 1m 36s\n",
      "320:\ttest: 0.7224310\ttest1: 0.7183540\tbest: 0.7183629 (318)\ttotal: 18.3s\tremaining: 1m 35s\n",
      "330:\ttest: 0.7228390\ttest1: 0.7186721\tbest: 0.7187975 (328)\ttotal: 18.9s\tremaining: 1m 35s\n",
      "340:\ttest: 0.7233183\ttest1: 0.7192445\tbest: 0.7192445 (340)\ttotal: 19.5s\tremaining: 1m 34s\n",
      "350:\ttest: 0.7238905\ttest1: 0.7193803\tbest: 0.7194646 (346)\ttotal: 20s\tremaining: 1m 34s\n",
      "360:\ttest: 0.7243948\ttest1: 0.7197633\tbest: 0.7197633 (360)\ttotal: 20.7s\tremaining: 1m 33s\n",
      "370:\ttest: 0.7250403\ttest1: 0.7199029\tbest: 0.7199029 (370)\ttotal: 21.3s\tremaining: 1m 33s\n",
      "380:\ttest: 0.7256366\ttest1: 0.7203191\tbest: 0.7203879 (378)\ttotal: 21.8s\tremaining: 1m 32s\n",
      "390:\ttest: 0.7262470\ttest1: 0.7207988\tbest: 0.7208017 (389)\ttotal: 22.4s\tremaining: 1m 32s\n",
      "400:\ttest: 0.7267902\ttest1: 0.7210037\tbest: 0.7212073 (399)\ttotal: 23s\tremaining: 1m 31s\n",
      "410:\ttest: 0.7272485\ttest1: 0.7214591\tbest: 0.7214591 (410)\ttotal: 23.5s\tremaining: 1m 30s\n",
      "420:\ttest: 0.7277015\ttest1: 0.7219423\tbest: 0.7219618 (416)\ttotal: 24.1s\tremaining: 1m 30s\n",
      "430:\ttest: 0.7280988\ttest1: 0.7218557\tbest: 0.7219618 (416)\ttotal: 24.7s\tremaining: 1m 29s\n",
      "440:\ttest: 0.7284670\ttest1: 0.7220934\tbest: 0.7222916 (437)\ttotal: 25.3s\tremaining: 1m 29s\n",
      "450:\ttest: 0.7288197\ttest1: 0.7224979\tbest: 0.7224979 (450)\ttotal: 25.8s\tremaining: 1m 28s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460:\ttest: 0.7293037\ttest1: 0.7225471\tbest: 0.7225471 (460)\ttotal: 26.5s\tremaining: 1m 28s\n",
      "470:\ttest: 0.7297675\ttest1: 0.7227193\tbest: 0.7227193 (470)\ttotal: 27.1s\tremaining: 1m 27s\n",
      "480:\ttest: 0.7301509\ttest1: 0.7228026\tbest: 0.7228026 (480)\ttotal: 27.6s\tremaining: 1m 27s\n",
      "490:\ttest: 0.7305738\ttest1: 0.7227329\tbest: 0.7228522 (481)\ttotal: 28.2s\tremaining: 1m 26s\n",
      "500:\ttest: 0.7309847\ttest1: 0.7232823\tbest: 0.7233326 (499)\ttotal: 28.8s\tremaining: 1m 26s\n",
      "510:\ttest: 0.7313871\ttest1: 0.7232490\tbest: 0.7233464 (508)\ttotal: 29.3s\tremaining: 1m 25s\n",
      "520:\ttest: 0.7317220\ttest1: 0.7233843\tbest: 0.7235199 (516)\ttotal: 29.9s\tremaining: 1m 24s\n",
      "530:\ttest: 0.7320980\ttest1: 0.7235663\tbest: 0.7235729 (525)\ttotal: 30.5s\tremaining: 1m 24s\n",
      "540:\ttest: 0.7324763\ttest1: 0.7238573\tbest: 0.7238573 (540)\ttotal: 31s\tremaining: 1m 23s\n",
      "550:\ttest: 0.7327321\ttest1: 0.7236867\tbest: 0.7238573 (540)\ttotal: 31.6s\tremaining: 1m 23s\n",
      "560:\ttest: 0.7330691\ttest1: 0.7238844\tbest: 0.7238932 (558)\ttotal: 32.2s\tremaining: 1m 22s\n",
      "570:\ttest: 0.7335553\ttest1: 0.7239517\tbest: 0.7240945 (566)\ttotal: 32.8s\tremaining: 1m 22s\n",
      "580:\ttest: 0.7338608\ttest1: 0.7241062\tbest: 0.7242952 (578)\ttotal: 33.4s\tremaining: 1m 21s\n",
      "590:\ttest: 0.7342108\ttest1: 0.7245607\tbest: 0.7245607 (590)\ttotal: 33.9s\tremaining: 1m 20s\n",
      "600:\ttest: 0.7345431\ttest1: 0.7246504\tbest: 0.7247812 (596)\ttotal: 34.5s\tremaining: 1m 20s\n",
      "610:\ttest: 0.7349016\ttest1: 0.7245693\tbest: 0.7247925 (602)\ttotal: 35s\tremaining: 1m 19s\n",
      "620:\ttest: 0.7352144\ttest1: 0.7244306\tbest: 0.7247925 (602)\ttotal: 35.6s\tremaining: 1m 19s\n",
      "630:\ttest: 0.7354196\ttest1: 0.7244304\tbest: 0.7247925 (602)\ttotal: 36.1s\tremaining: 1m 18s\n",
      "640:\ttest: 0.7357288\ttest1: 0.7243704\tbest: 0.7247925 (602)\ttotal: 36.7s\tremaining: 1m 17s\n",
      "650:\ttest: 0.7360852\ttest1: 0.7244502\tbest: 0.7247925 (602)\ttotal: 37.3s\tremaining: 1m 17s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7247924512\n",
      "bestIteration = 602\n",
      "\n",
      "Shrink model to first 603 iterations.\n",
      "Fold 2, Valid score = 0.72479\n",
      "0:\ttest: 0.6501249\ttest1: 0.6542465\tbest: 0.6542465 (0)\ttotal: 62.4ms\tremaining: 2m 4s\n",
      "10:\ttest: 0.6999919\ttest1: 0.6995284\tbest: 0.6997712 (9)\ttotal: 623ms\tremaining: 1m 52s\n",
      "20:\ttest: 0.7016224\ttest1: 0.7027496\tbest: 0.7031409 (16)\ttotal: 1.15s\tremaining: 1m 48s\n",
      "30:\ttest: 0.7038973\ttest1: 0.7051895\tbest: 0.7051895 (30)\ttotal: 1.7s\tremaining: 1m 48s\n",
      "40:\ttest: 0.7053695\ttest1: 0.7062226\tbest: 0.7062226 (40)\ttotal: 2.24s\tremaining: 1m 46s\n",
      "50:\ttest: 0.7065708\ttest1: 0.7074257\tbest: 0.7074436 (49)\ttotal: 2.78s\tremaining: 1m 46s\n",
      "60:\ttest: 0.7075159\ttest1: 0.7090235\tbest: 0.7090235 (60)\ttotal: 3.36s\tremaining: 1m 46s\n",
      "70:\ttest: 0.7091098\ttest1: 0.7099955\tbest: 0.7099955 (70)\ttotal: 3.9s\tremaining: 1m 45s\n",
      "80:\ttest: 0.7099368\ttest1: 0.7107275\tbest: 0.7110314 (79)\ttotal: 4.45s\tremaining: 1m 45s\n",
      "90:\ttest: 0.7104741\ttest1: 0.7110520\tbest: 0.7110520 (90)\ttotal: 5.02s\tremaining: 1m 45s\n",
      "100:\ttest: 0.7108050\ttest1: 0.7108936\tbest: 0.7111410 (93)\ttotal: 5.63s\tremaining: 1m 45s\n",
      "110:\ttest: 0.7112943\ttest1: 0.7112500\tbest: 0.7116637 (106)\ttotal: 6.18s\tremaining: 1m 45s\n",
      "120:\ttest: 0.7112218\ttest1: 0.7109540\tbest: 0.7116637 (106)\ttotal: 6.74s\tremaining: 1m 44s\n",
      "130:\ttest: 0.7117531\ttest1: 0.7119501\tbest: 0.7119501 (130)\ttotal: 7.29s\tremaining: 1m 43s\n",
      "140:\ttest: 0.7127946\ttest1: 0.7126921\tbest: 0.7126921 (140)\ttotal: 7.83s\tremaining: 1m 43s\n",
      "150:\ttest: 0.7130503\ttest1: 0.7128930\tbest: 0.7131497 (147)\ttotal: 8.35s\tremaining: 1m 42s\n",
      "160:\ttest: 0.7136786\ttest1: 0.7133905\tbest: 0.7134672 (155)\ttotal: 8.96s\tremaining: 1m 42s\n",
      "170:\ttest: 0.7140908\ttest1: 0.7140427\tbest: 0.7141816 (164)\ttotal: 9.53s\tremaining: 1m 41s\n",
      "180:\ttest: 0.7142126\ttest1: 0.7140687\tbest: 0.7141816 (164)\ttotal: 10.1s\tremaining: 1m 41s\n",
      "190:\ttest: 0.7151231\ttest1: 0.7150989\tbest: 0.7150989 (190)\ttotal: 10.7s\tremaining: 1m 41s\n",
      "200:\ttest: 0.7157435\ttest1: 0.7153132\tbest: 0.7155402 (198)\ttotal: 11.4s\tremaining: 1m 41s\n",
      "210:\ttest: 0.7165103\ttest1: 0.7165357\tbest: 0.7165357 (210)\ttotal: 12s\tremaining: 1m 41s\n",
      "220:\ttest: 0.7169484\ttest1: 0.7163868\tbest: 0.7165357 (210)\ttotal: 12.5s\tremaining: 1m 41s\n",
      "230:\ttest: 0.7174100\ttest1: 0.7167337\tbest: 0.7167337 (230)\ttotal: 13.1s\tremaining: 1m 40s\n",
      "240:\ttest: 0.7180001\ttest1: 0.7171285\tbest: 0.7171285 (240)\ttotal: 13.7s\tremaining: 1m 39s\n",
      "250:\ttest: 0.7185820\ttest1: 0.7174272\tbest: 0.7174272 (250)\ttotal: 14.3s\tremaining: 1m 39s\n",
      "260:\ttest: 0.7192732\ttest1: 0.7178236\tbest: 0.7178422 (257)\ttotal: 14.9s\tremaining: 1m 39s\n",
      "270:\ttest: 0.7195054\ttest1: 0.7188752\tbest: 0.7188752 (270)\ttotal: 15.4s\tremaining: 1m 38s\n",
      "280:\ttest: 0.7200905\ttest1: 0.7194565\tbest: 0.7194565 (280)\ttotal: 16s\tremaining: 1m 37s\n",
      "290:\ttest: 0.7205411\ttest1: 0.7198012\tbest: 0.7198012 (290)\ttotal: 16.6s\tremaining: 1m 37s\n",
      "300:\ttest: 0.7208347\ttest1: 0.7200861\tbest: 0.7200861 (300)\ttotal: 17.2s\tremaining: 1m 36s\n",
      "310:\ttest: 0.7213967\ttest1: 0.7204577\tbest: 0.7204577 (310)\ttotal: 17.8s\tremaining: 1m 36s\n",
      "320:\ttest: 0.7219779\ttest1: 0.7208001\tbest: 0.7210663 (319)\ttotal: 18.3s\tremaining: 1m 35s\n",
      "330:\ttest: 0.7225332\ttest1: 0.7214169\tbest: 0.7214857 (325)\ttotal: 18.9s\tremaining: 1m 35s\n",
      "340:\ttest: 0.7231749\ttest1: 0.7220293\tbest: 0.7220293 (340)\ttotal: 19.4s\tremaining: 1m 34s\n",
      "350:\ttest: 0.7236002\ttest1: 0.7225481\tbest: 0.7225481 (350)\ttotal: 20s\tremaining: 1m 34s\n",
      "360:\ttest: 0.7240429\ttest1: 0.7228452\tbest: 0.7228537 (359)\ttotal: 20.6s\tremaining: 1m 33s\n",
      "370:\ttest: 0.7245023\ttest1: 0.7232509\tbest: 0.7232979 (369)\ttotal: 21.2s\tremaining: 1m 32s\n",
      "380:\ttest: 0.7248799\ttest1: 0.7236940\tbest: 0.7237883 (378)\ttotal: 21.8s\tremaining: 1m 32s\n",
      "390:\ttest: 0.7252849\ttest1: 0.7237386\tbest: 0.7238369 (389)\ttotal: 22.4s\tremaining: 1m 32s\n",
      "400:\ttest: 0.7259926\ttest1: 0.7240442\tbest: 0.7241984 (399)\ttotal: 23s\tremaining: 1m 31s\n",
      "410:\ttest: 0.7263476\ttest1: 0.7245431\tbest: 0.7245477 (409)\ttotal: 23.5s\tremaining: 1m 30s\n",
      "420:\ttest: 0.7269530\ttest1: 0.7246393\tbest: 0.7248051 (419)\ttotal: 24.1s\tremaining: 1m 30s\n",
      "430:\ttest: 0.7274584\ttest1: 0.7252689\tbest: 0.7252735 (429)\ttotal: 24.6s\tremaining: 1m 29s\n",
      "440:\ttest: 0.7279833\ttest1: 0.7258743\tbest: 0.7258765 (438)\ttotal: 25.2s\tremaining: 1m 29s\n",
      "450:\ttest: 0.7283993\ttest1: 0.7258762\tbest: 0.7258827 (443)\ttotal: 25.8s\tremaining: 1m 28s\n",
      "460:\ttest: 0.7287120\ttest1: 0.7259932\tbest: 0.7259932 (460)\ttotal: 26.4s\tremaining: 1m 28s\n",
      "470:\ttest: 0.7290231\ttest1: 0.7262010\tbest: 0.7262108 (469)\ttotal: 26.9s\tremaining: 1m 27s\n",
      "480:\ttest: 0.7295527\ttest1: 0.7261154\tbest: 0.7263097 (471)\ttotal: 27.6s\tremaining: 1m 27s\n",
      "490:\ttest: 0.7301194\ttest1: 0.7266454\tbest: 0.7266943 (488)\ttotal: 28.2s\tremaining: 1m 26s\n",
      "500:\ttest: 0.7304347\ttest1: 0.7267904\tbest: 0.7267904 (500)\ttotal: 28.8s\tremaining: 1m 26s\n",
      "510:\ttest: 0.7307375\ttest1: 0.7268380\tbest: 0.7268663 (509)\ttotal: 29.3s\tremaining: 1m 25s\n",
      "520:\ttest: 0.7308870\ttest1: 0.7270359\tbest: 0.7270367 (518)\ttotal: 29.9s\tremaining: 1m 24s\n",
      "530:\ttest: 0.7312655\ttest1: 0.7271313\tbest: 0.7271419 (528)\ttotal: 30.4s\tremaining: 1m 24s\n",
      "540:\ttest: 0.7314764\ttest1: 0.7272988\tbest: 0.7272988 (540)\ttotal: 31s\tremaining: 1m 23s\n",
      "550:\ttest: 0.7318121\ttest1: 0.7273616\tbest: 0.7274592 (547)\ttotal: 31.6s\tremaining: 1m 23s\n",
      "560:\ttest: 0.7322409\ttest1: 0.7277050\tbest: 0.7277735 (557)\ttotal: 32.1s\tremaining: 1m 22s\n",
      "570:\ttest: 0.7326160\ttest1: 0.7280661\tbest: 0.7281349 (568)\ttotal: 32.7s\tremaining: 1m 21s\n",
      "580:\ttest: 0.7329249\ttest1: 0.7285225\tbest: 0.7286188 (579)\ttotal: 33.3s\tremaining: 1m 21s\n",
      "590:\ttest: 0.7332400\ttest1: 0.7286960\tbest: 0.7287260 (589)\ttotal: 33.9s\tremaining: 1m 20s\n",
      "600:\ttest: 0.7336742\ttest1: 0.7289589\tbest: 0.7289589 (600)\ttotal: 34.4s\tremaining: 1m 20s\n",
      "610:\ttest: 0.7339766\ttest1: 0.7289505\tbest: 0.7290318 (608)\ttotal: 35s\tremaining: 1m 19s\n",
      "620:\ttest: 0.7342145\ttest1: 0.7287314\tbest: 0.7290318 (608)\ttotal: 35.5s\tremaining: 1m 18s\n",
      "630:\ttest: 0.7345509\ttest1: 0.7288571\tbest: 0.7290318 (608)\ttotal: 36.1s\tremaining: 1m 18s\n",
      "640:\ttest: 0.7348576\ttest1: 0.7288465\tbest: 0.7290318 (608)\ttotal: 36.7s\tremaining: 1m 17s\n",
      "650:\ttest: 0.7351723\ttest1: 0.7288772\tbest: 0.7290318 (608)\ttotal: 37.3s\tremaining: 1m 17s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7290318417\n",
      "bestIteration = 608\n",
      "\n",
      "Shrink model to first 609 iterations.\n",
      "Fold 3, Valid score = 0.72903\n",
      "0:\ttest: 0.6655136\ttest1: 0.6622001\tbest: 0.6622001 (0)\ttotal: 60.1ms\tremaining: 2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:\ttest: 0.6990736\ttest1: 0.6953247\tbest: 0.6955074 (7)\ttotal: 677ms\tremaining: 2m 2s\n",
      "20:\ttest: 0.7022210\ttest1: 0.6964507\tbest: 0.6973307 (17)\ttotal: 1.27s\tremaining: 2m\n",
      "30:\ttest: 0.7053189\ttest1: 0.7003754\tbest: 0.7003754 (30)\ttotal: 1.82s\tremaining: 1m 55s\n",
      "40:\ttest: 0.7065836\ttest1: 0.7017322\tbest: 0.7017322 (40)\ttotal: 2.38s\tremaining: 1m 53s\n",
      "50:\ttest: 0.7073620\ttest1: 0.7024247\tbest: 0.7026669 (46)\ttotal: 2.94s\tremaining: 1m 52s\n",
      "60:\ttest: 0.7080466\ttest1: 0.7036449\tbest: 0.7037276 (59)\ttotal: 3.5s\tremaining: 1m 51s\n",
      "70:\ttest: 0.7087878\ttest1: 0.7039325\tbest: 0.7041869 (63)\ttotal: 4.04s\tremaining: 1m 49s\n",
      "80:\ttest: 0.7095496\ttest1: 0.7039574\tbest: 0.7041869 (63)\ttotal: 4.65s\tremaining: 1m 50s\n",
      "90:\ttest: 0.7101221\ttest1: 0.7041571\tbest: 0.7041869 (63)\ttotal: 5.19s\tremaining: 1m 48s\n",
      "100:\ttest: 0.7107977\ttest1: 0.7051310\tbest: 0.7051310 (100)\ttotal: 5.73s\tremaining: 1m 47s\n",
      "110:\ttest: 0.7121658\ttest1: 0.7054288\tbest: 0.7054288 (110)\ttotal: 6.35s\tremaining: 1m 47s\n",
      "120:\ttest: 0.7121356\ttest1: 0.7054418\tbest: 0.7056290 (114)\ttotal: 6.94s\tremaining: 1m 47s\n",
      "130:\ttest: 0.7127587\ttest1: 0.7056502\tbest: 0.7057537 (127)\ttotal: 7.5s\tremaining: 1m 46s\n",
      "140:\ttest: 0.7131781\ttest1: 0.7058215\tbest: 0.7060745 (134)\ttotal: 8.03s\tremaining: 1m 45s\n",
      "150:\ttest: 0.7141559\ttest1: 0.7059195\tbest: 0.7062622 (146)\ttotal: 8.58s\tremaining: 1m 45s\n",
      "160:\ttest: 0.7144337\ttest1: 0.7066026\tbest: 0.7067125 (159)\ttotal: 9.12s\tremaining: 1m 44s\n",
      "170:\ttest: 0.7147756\ttest1: 0.7069211\tbest: 0.7069211 (170)\ttotal: 9.67s\tremaining: 1m 43s\n",
      "180:\ttest: 0.7152430\ttest1: 0.7072110\tbest: 0.7072162 (179)\ttotal: 10.3s\tremaining: 1m 43s\n",
      "190:\ttest: 0.7159066\ttest1: 0.7072289\tbest: 0.7072457 (184)\ttotal: 10.8s\tremaining: 1m 42s\n",
      "200:\ttest: 0.7169480\ttest1: 0.7077291\tbest: 0.7077342 (199)\ttotal: 11.4s\tremaining: 1m 42s\n",
      "210:\ttest: 0.7173615\ttest1: 0.7080325\tbest: 0.7080872 (209)\ttotal: 12s\tremaining: 1m 41s\n",
      "220:\ttest: 0.7182126\ttest1: 0.7084203\tbest: 0.7084203 (220)\ttotal: 12.7s\tremaining: 1m 41s\n",
      "230:\ttest: 0.7189162\ttest1: 0.7085296\tbest: 0.7088067 (225)\ttotal: 13.2s\tremaining: 1m 41s\n",
      "240:\ttest: 0.7195281\ttest1: 0.7088215\tbest: 0.7088867 (239)\ttotal: 13.8s\tremaining: 1m 40s\n",
      "250:\ttest: 0.7201684\ttest1: 0.7093453\tbest: 0.7093453 (250)\ttotal: 14.3s\tremaining: 1m 39s\n",
      "260:\ttest: 0.7208279\ttest1: 0.7092383\tbest: 0.7094620 (253)\ttotal: 14.9s\tremaining: 1m 39s\n",
      "270:\ttest: 0.7212582\ttest1: 0.7095715\tbest: 0.7095715 (270)\ttotal: 15.5s\tremaining: 1m 38s\n",
      "280:\ttest: 0.7217595\ttest1: 0.7098429\tbest: 0.7099186 (276)\ttotal: 16.1s\tremaining: 1m 38s\n",
      "290:\ttest: 0.7223875\ttest1: 0.7103085\tbest: 0.7103085 (290)\ttotal: 16.7s\tremaining: 1m 37s\n",
      "300:\ttest: 0.7231701\ttest1: 0.7107464\tbest: 0.7107625 (299)\ttotal: 17.2s\tremaining: 1m 37s\n",
      "310:\ttest: 0.7236363\ttest1: 0.7111079\tbest: 0.7111079 (310)\ttotal: 17.9s\tremaining: 1m 37s\n",
      "320:\ttest: 0.7240746\ttest1: 0.7113663\tbest: 0.7114789 (316)\ttotal: 18.5s\tremaining: 1m 36s\n",
      "330:\ttest: 0.7247229\ttest1: 0.7116715\tbest: 0.7116715 (330)\ttotal: 19.1s\tremaining: 1m 36s\n",
      "340:\ttest: 0.7254149\ttest1: 0.7119826\tbest: 0.7120580 (339)\ttotal: 19.7s\tremaining: 1m 36s\n",
      "350:\ttest: 0.7259750\ttest1: 0.7122503\tbest: 0.7123322 (349)\ttotal: 20.3s\tremaining: 1m 35s\n",
      "360:\ttest: 0.7265443\ttest1: 0.7126001\tbest: 0.7126001 (360)\ttotal: 20.9s\tremaining: 1m 34s\n",
      "370:\ttest: 0.7270580\ttest1: 0.7127757\tbest: 0.7127757 (370)\ttotal: 21.5s\tremaining: 1m 34s\n",
      "380:\ttest: 0.7273105\ttest1: 0.7129958\tbest: 0.7129958 (380)\ttotal: 22.1s\tremaining: 1m 33s\n",
      "390:\ttest: 0.7278806\ttest1: 0.7134633\tbest: 0.7134633 (390)\ttotal: 22.7s\tremaining: 1m 33s\n",
      "400:\ttest: 0.7282884\ttest1: 0.7137571\tbest: 0.7137571 (400)\ttotal: 23.3s\tremaining: 1m 32s\n",
      "410:\ttest: 0.7285911\ttest1: 0.7142807\tbest: 0.7142807 (410)\ttotal: 23.9s\tremaining: 1m 32s\n",
      "420:\ttest: 0.7290543\ttest1: 0.7144847\tbest: 0.7145215 (419)\ttotal: 24.5s\tremaining: 1m 31s\n",
      "430:\ttest: 0.7293959\ttest1: 0.7149940\tbest: 0.7149940 (430)\ttotal: 25s\tremaining: 1m 31s\n",
      "440:\ttest: 0.7298061\ttest1: 0.7151748\tbest: 0.7151748 (440)\ttotal: 25.6s\tremaining: 1m 30s\n",
      "450:\ttest: 0.7304154\ttest1: 0.7152746\tbest: 0.7152746 (450)\ttotal: 26.1s\tremaining: 1m 29s\n",
      "460:\ttest: 0.7308657\ttest1: 0.7153737\tbest: 0.7154594 (459)\ttotal: 26.7s\tremaining: 1m 29s\n",
      "470:\ttest: 0.7312108\ttest1: 0.7155254\tbest: 0.7155945 (462)\ttotal: 27.3s\tremaining: 1m 28s\n",
      "480:\ttest: 0.7316727\ttest1: 0.7158043\tbest: 0.7158043 (480)\ttotal: 27.9s\tremaining: 1m 27s\n",
      "490:\ttest: 0.7320279\ttest1: 0.7159738\tbest: 0.7159738 (490)\ttotal: 28.5s\tremaining: 1m 27s\n",
      "500:\ttest: 0.7323520\ttest1: 0.7159872\tbest: 0.7160150 (498)\ttotal: 29.1s\tremaining: 1m 27s\n",
      "510:\ttest: 0.7328034\ttest1: 0.7162041\tbest: 0.7162416 (508)\ttotal: 29.7s\tremaining: 1m 26s\n",
      "520:\ttest: 0.7332817\ttest1: 0.7164626\tbest: 0.7165289 (517)\ttotal: 30.2s\tremaining: 1m 25s\n",
      "530:\ttest: 0.7336721\ttest1: 0.7167776\tbest: 0.7167920 (525)\ttotal: 30.8s\tremaining: 1m 25s\n",
      "540:\ttest: 0.7338937\ttest1: 0.7168260\tbest: 0.7168989 (536)\ttotal: 31.4s\tremaining: 1m 24s\n",
      "550:\ttest: 0.7342832\ttest1: 0.7168646\tbest: 0.7169406 (547)\ttotal: 31.9s\tremaining: 1m 23s\n",
      "560:\ttest: 0.7345553\ttest1: 0.7169935\tbest: 0.7170131 (556)\ttotal: 32.5s\tremaining: 1m 23s\n",
      "570:\ttest: 0.7348533\ttest1: 0.7169907\tbest: 0.7170269 (561)\ttotal: 33.1s\tremaining: 1m 22s\n",
      "580:\ttest: 0.7352440\ttest1: 0.7169721\tbest: 0.7171437 (579)\ttotal: 33.6s\tremaining: 1m 22s\n",
      "590:\ttest: 0.7354585\ttest1: 0.7172327\tbest: 0.7172500 (589)\ttotal: 34.2s\tremaining: 1m 21s\n",
      "600:\ttest: 0.7357249\ttest1: 0.7172672\tbest: 0.7173655 (593)\ttotal: 34.8s\tremaining: 1m 21s\n",
      "610:\ttest: 0.7359650\ttest1: 0.7172897\tbest: 0.7173655 (593)\ttotal: 35.4s\tremaining: 1m 20s\n",
      "620:\ttest: 0.7363641\ttest1: 0.7173163\tbest: 0.7175030 (617)\ttotal: 36s\tremaining: 1m 19s\n",
      "630:\ttest: 0.7366730\ttest1: 0.7175129\tbest: 0.7175929 (629)\ttotal: 36.5s\tremaining: 1m 19s\n",
      "640:\ttest: 0.7369859\ttest1: 0.7178207\tbest: 0.7178344 (637)\ttotal: 37.1s\tremaining: 1m 18s\n",
      "650:\ttest: 0.7373746\ttest1: 0.7181870\tbest: 0.7181911 (648)\ttotal: 37.6s\tremaining: 1m 18s\n",
      "660:\ttest: 0.7376778\ttest1: 0.7183287\tbest: 0.7183339 (658)\ttotal: 38.2s\tremaining: 1m 17s\n",
      "670:\ttest: 0.7380076\ttest1: 0.7185660\tbest: 0.7185722 (669)\ttotal: 38.8s\tremaining: 1m 16s\n",
      "680:\ttest: 0.7383337\ttest1: 0.7187313\tbest: 0.7187345 (679)\ttotal: 39.3s\tremaining: 1m 16s\n",
      "690:\ttest: 0.7386121\ttest1: 0.7188203\tbest: 0.7188256 (689)\ttotal: 40s\tremaining: 1m 15s\n",
      "700:\ttest: 0.7389441\ttest1: 0.7189220\tbest: 0.7189220 (700)\ttotal: 40.7s\tremaining: 1m 15s\n",
      "710:\ttest: 0.7392415\ttest1: 0.7189796\tbest: 0.7189796 (710)\ttotal: 41.3s\tremaining: 1m 14s\n",
      "720:\ttest: 0.7395541\ttest1: 0.7190123\tbest: 0.7190808 (716)\ttotal: 41.9s\tremaining: 1m 14s\n",
      "730:\ttest: 0.7396785\ttest1: 0.7191416\tbest: 0.7191547 (729)\ttotal: 42.5s\tremaining: 1m 13s\n",
      "740:\ttest: 0.7399783\ttest1: 0.7191060\tbest: 0.7191980 (738)\ttotal: 43.1s\tremaining: 1m 13s\n",
      "750:\ttest: 0.7403108\ttest1: 0.7192269\tbest: 0.7192269 (750)\ttotal: 43.7s\tremaining: 1m 12s\n",
      "760:\ttest: 0.7406240\ttest1: 0.7193259\tbest: 0.7193259 (760)\ttotal: 44.3s\tremaining: 1m 12s\n",
      "770:\ttest: 0.7408607\ttest1: 0.7193788\tbest: 0.7193788 (770)\ttotal: 44.9s\tremaining: 1m 11s\n",
      "780:\ttest: 0.7410951\ttest1: 0.7194285\tbest: 0.7194958 (772)\ttotal: 45.5s\tremaining: 1m 11s\n",
      "790:\ttest: 0.7413770\ttest1: 0.7194514\tbest: 0.7195180 (785)\ttotal: 46.1s\tremaining: 1m 10s\n",
      "800:\ttest: 0.7414791\ttest1: 0.7195201\tbest: 0.7195549 (796)\ttotal: 46.7s\tremaining: 1m 9s\n",
      "810:\ttest: 0.7417120\ttest1: 0.7195251\tbest: 0.7195717 (803)\ttotal: 47.2s\tremaining: 1m 9s\n",
      "820:\ttest: 0.7420627\ttest1: 0.7195576\tbest: 0.7196140 (812)\ttotal: 47.8s\tremaining: 1m 8s\n",
      "830:\ttest: 0.7423653\ttest1: 0.7198108\tbest: 0.7198108 (830)\ttotal: 48.4s\tremaining: 1m 8s\n",
      "840:\ttest: 0.7425558\ttest1: 0.7198669\tbest: 0.7198669 (840)\ttotal: 48.9s\tremaining: 1m 7s\n",
      "850:\ttest: 0.7427601\ttest1: 0.7198239\tbest: 0.7199804 (844)\ttotal: 49.6s\tremaining: 1m 6s\n",
      "860:\ttest: 0.7430486\ttest1: 0.7198653\tbest: 0.7199804 (844)\ttotal: 50.1s\tremaining: 1m 6s\n",
      "870:\ttest: 0.7432806\ttest1: 0.7198886\tbest: 0.7200767 (865)\ttotal: 50.7s\tremaining: 1m 5s\n",
      "880:\ttest: 0.7435257\ttest1: 0.7198028\tbest: 0.7200767 (865)\ttotal: 51.3s\tremaining: 1m 5s\n",
      "890:\ttest: 0.7438097\ttest1: 0.7199712\tbest: 0.7200767 (865)\ttotal: 51.9s\tremaining: 1m 4s\n",
      "900:\ttest: 0.7440537\ttest1: 0.7202142\tbest: 0.7202142 (900)\ttotal: 52.5s\tremaining: 1m 4s\n",
      "910:\ttest: 0.7443809\ttest1: 0.7202502\tbest: 0.7203473 (908)\ttotal: 53s\tremaining: 1m 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920:\ttest: 0.7445928\ttest1: 0.7203640\tbest: 0.7204805 (916)\ttotal: 53.6s\tremaining: 1m 2s\n",
      "930:\ttest: 0.7448816\ttest1: 0.7204978\tbest: 0.7205003 (929)\ttotal: 54.1s\tremaining: 1m 2s\n",
      "940:\ttest: 0.7450549\ttest1: 0.7205697\tbest: 0.7206637 (937)\ttotal: 54.7s\tremaining: 1m 1s\n",
      "950:\ttest: 0.7453653\ttest1: 0.7208378\tbest: 0.7208467 (948)\ttotal: 55.3s\tremaining: 1m\n",
      "960:\ttest: 0.7455693\ttest1: 0.7208726\tbest: 0.7209630 (954)\ttotal: 55.8s\tremaining: 1m\n",
      "970:\ttest: 0.7457516\ttest1: 0.7210903\tbest: 0.7211162 (969)\ttotal: 56.4s\tremaining: 59.8s\n",
      "980:\ttest: 0.7460224\ttest1: 0.7210419\tbest: 0.7211162 (969)\ttotal: 57s\tremaining: 59.2s\n",
      "990:\ttest: 0.7461580\ttest1: 0.7209895\tbest: 0.7211162 (969)\ttotal: 57.6s\tremaining: 58.6s\n",
      "1000:\ttest: 0.7464426\ttest1: 0.7210754\tbest: 0.7211301 (998)\ttotal: 58.1s\tremaining: 58s\n",
      "1010:\ttest: 0.7467488\ttest1: 0.7210901\tbest: 0.7211301 (998)\ttotal: 58.7s\tremaining: 57.4s\n",
      "1020:\ttest: 0.7470027\ttest1: 0.7209392\tbest: 0.7211301 (998)\ttotal: 59.2s\tremaining: 56.8s\n",
      "1030:\ttest: 0.7472336\ttest1: 0.7210458\tbest: 0.7211301 (998)\ttotal: 59.8s\tremaining: 56.2s\n",
      "1040:\ttest: 0.7474688\ttest1: 0.7210293\tbest: 0.7211301 (998)\ttotal: 1m\tremaining: 55.6s\n",
      "1050:\ttest: 0.7477272\ttest1: 0.7211324\tbest: 0.7211644 (1049)\ttotal: 1m\tremaining: 55s\n",
      "1060:\ttest: 0.7479608\ttest1: 0.7213507\tbest: 0.7213507 (1060)\ttotal: 1m 1s\tremaining: 54.4s\n",
      "1070:\ttest: 0.7481112\ttest1: 0.7211214\tbest: 0.7213604 (1063)\ttotal: 1m 2s\tremaining: 53.8s\n",
      "1080:\ttest: 0.7483451\ttest1: 0.7213554\tbest: 0.7213950 (1077)\ttotal: 1m 2s\tremaining: 53.3s\n",
      "1090:\ttest: 0.7485764\ttest1: 0.7212877\tbest: 0.7213950 (1077)\ttotal: 1m 3s\tremaining: 52.8s\n",
      "1100:\ttest: 0.7487816\ttest1: 0.7213195\tbest: 0.7213950 (1077)\ttotal: 1m 3s\tremaining: 52.2s\n",
      "1110:\ttest: 0.7489696\ttest1: 0.7213039\tbest: 0.7213950 (1077)\ttotal: 1m 4s\tremaining: 51.6s\n",
      "1120:\ttest: 0.7491408\ttest1: 0.7213687\tbest: 0.7213950 (1077)\ttotal: 1m 5s\tremaining: 51s\n",
      "1130:\ttest: 0.7493387\ttest1: 0.7215046\tbest: 0.7215490 (1125)\ttotal: 1m 5s\tremaining: 50.4s\n",
      "1140:\ttest: 0.7496195\ttest1: 0.7214516\tbest: 0.7215662 (1135)\ttotal: 1m 6s\tremaining: 49.8s\n",
      "1150:\ttest: 0.7497601\ttest1: 0.7214999\tbest: 0.7215662 (1135)\ttotal: 1m 6s\tremaining: 49.2s\n",
      "1160:\ttest: 0.7500992\ttest1: 0.7213562\tbest: 0.7215662 (1135)\ttotal: 1m 7s\tremaining: 48.6s\n",
      "1170:\ttest: 0.7502892\ttest1: 0.7213921\tbest: 0.7215662 (1135)\ttotal: 1m 7s\tremaining: 48.1s\n",
      "1180:\ttest: 0.7505532\ttest1: 0.7215072\tbest: 0.7215662 (1135)\ttotal: 1m 8s\tremaining: 47.5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7215662498\n",
      "bestIteration = 1135\n",
      "\n",
      "Shrink model to first 1136 iterations.\n",
      "Fold 4, Valid score = 0.72157\n",
      "0:\ttest: 0.6670023\ttest1: 0.6690238\tbest: 0.6690238 (0)\ttotal: 57.4ms\tremaining: 1m 54s\n",
      "10:\ttest: 0.6983688\ttest1: 0.6961050\tbest: 0.6961345 (9)\ttotal: 603ms\tremaining: 1m 48s\n",
      "20:\ttest: 0.7008203\ttest1: 0.6998245\tbest: 0.6998245 (20)\ttotal: 1.13s\tremaining: 1m 46s\n",
      "30:\ttest: 0.7048349\ttest1: 0.7036580\tbest: 0.7036580 (30)\ttotal: 1.68s\tremaining: 1m 46s\n",
      "40:\ttest: 0.7069954\ttest1: 0.7039963\tbest: 0.7040998 (36)\ttotal: 2.25s\tremaining: 1m 47s\n",
      "50:\ttest: 0.7074240\ttest1: 0.7043277\tbest: 0.7046371 (43)\ttotal: 2.84s\tremaining: 1m 48s\n",
      "60:\ttest: 0.7078785\ttest1: 0.7045398\tbest: 0.7046428 (58)\ttotal: 3.41s\tremaining: 1m 48s\n",
      "70:\ttest: 0.7084630\ttest1: 0.7052491\tbest: 0.7055964 (69)\ttotal: 3.96s\tremaining: 1m 47s\n",
      "80:\ttest: 0.7091591\ttest1: 0.7059389\tbest: 0.7059389 (80)\ttotal: 4.55s\tremaining: 1m 47s\n",
      "90:\ttest: 0.7095115\ttest1: 0.7058730\tbest: 0.7060746 (81)\ttotal: 5.14s\tremaining: 1m 47s\n",
      "100:\ttest: 0.7103723\ttest1: 0.7069264\tbest: 0.7069264 (100)\ttotal: 5.72s\tremaining: 1m 47s\n",
      "110:\ttest: 0.7115691\ttest1: 0.7076414\tbest: 0.7076414 (110)\ttotal: 6.38s\tremaining: 1m 48s\n",
      "120:\ttest: 0.7115759\ttest1: 0.7077674\tbest: 0.7078789 (118)\ttotal: 7.03s\tremaining: 1m 49s\n",
      "130:\ttest: 0.7120865\ttest1: 0.7079535\tbest: 0.7081298 (129)\ttotal: 7.6s\tremaining: 1m 48s\n",
      "140:\ttest: 0.7122187\ttest1: 0.7081095\tbest: 0.7082457 (133)\ttotal: 8.18s\tremaining: 1m 47s\n",
      "150:\ttest: 0.7129746\ttest1: 0.7088143\tbest: 0.7088143 (150)\ttotal: 8.74s\tremaining: 1m 46s\n",
      "160:\ttest: 0.7136031\ttest1: 0.7093084\tbest: 0.7095155 (158)\ttotal: 9.28s\tremaining: 1m 45s\n",
      "170:\ttest: 0.7143653\ttest1: 0.7104410\tbest: 0.7104410 (170)\ttotal: 9.85s\tremaining: 1m 45s\n",
      "180:\ttest: 0.7146520\ttest1: 0.7105415\tbest: 0.7105696 (178)\ttotal: 10.5s\tremaining: 1m 45s\n",
      "190:\ttest: 0.7149492\ttest1: 0.7111677\tbest: 0.7111677 (190)\ttotal: 11.1s\tremaining: 1m 44s\n",
      "200:\ttest: 0.7157954\ttest1: 0.7111899\tbest: 0.7113442 (198)\ttotal: 11.6s\tremaining: 1m 44s\n",
      "210:\ttest: 0.7162849\ttest1: 0.7119639\tbest: 0.7119639 (210)\ttotal: 12.2s\tremaining: 1m 43s\n",
      "220:\ttest: 0.7170264\ttest1: 0.7121289\tbest: 0.7124731 (219)\ttotal: 12.7s\tremaining: 1m 42s\n",
      "230:\ttest: 0.7175655\ttest1: 0.7124211\tbest: 0.7124731 (219)\ttotal: 13.3s\tremaining: 1m 41s\n",
      "240:\ttest: 0.7183228\ttest1: 0.7125802\tbest: 0.7125802 (240)\ttotal: 13.9s\tremaining: 1m 41s\n",
      "250:\ttest: 0.7190971\ttest1: 0.7135174\tbest: 0.7135174 (250)\ttotal: 14.5s\tremaining: 1m 40s\n",
      "260:\ttest: 0.7195863\ttest1: 0.7138621\tbest: 0.7138621 (260)\ttotal: 15s\tremaining: 1m 39s\n",
      "270:\ttest: 0.7199868\ttest1: 0.7143178\tbest: 0.7143945 (269)\ttotal: 15.6s\tremaining: 1m 39s\n",
      "280:\ttest: 0.7206793\ttest1: 0.7150278\tbest: 0.7150278 (280)\ttotal: 16.2s\tremaining: 1m 39s\n",
      "290:\ttest: 0.7212061\ttest1: 0.7155026\tbest: 0.7155026 (290)\ttotal: 16.8s\tremaining: 1m 38s\n",
      "300:\ttest: 0.7218266\ttest1: 0.7159561\tbest: 0.7161072 (299)\ttotal: 17.3s\tremaining: 1m 37s\n",
      "310:\ttest: 0.7222833\ttest1: 0.7164423\tbest: 0.7164423 (310)\ttotal: 17.9s\tremaining: 1m 37s\n",
      "320:\ttest: 0.7227297\ttest1: 0.7164996\tbest: 0.7166144 (317)\ttotal: 18.5s\tremaining: 1m 36s\n",
      "330:\ttest: 0.7233189\ttest1: 0.7170699\tbest: 0.7170876 (327)\ttotal: 19s\tremaining: 1m 35s\n",
      "340:\ttest: 0.7237788\ttest1: 0.7172453\tbest: 0.7172798 (333)\ttotal: 19.6s\tremaining: 1m 35s\n",
      "350:\ttest: 0.7240180\ttest1: 0.7174955\tbest: 0.7174955 (350)\ttotal: 20.2s\tremaining: 1m 34s\n",
      "360:\ttest: 0.7246816\ttest1: 0.7179067\tbest: 0.7179067 (360)\ttotal: 20.8s\tremaining: 1m 34s\n",
      "370:\ttest: 0.7251411\ttest1: 0.7183833\tbest: 0.7183833 (370)\ttotal: 21.4s\tremaining: 1m 34s\n",
      "380:\ttest: 0.7254651\ttest1: 0.7184773\tbest: 0.7185130 (379)\ttotal: 22s\tremaining: 1m 33s\n",
      "390:\ttest: 0.7259678\ttest1: 0.7185405\tbest: 0.7185498 (388)\ttotal: 22.6s\tremaining: 1m 33s\n",
      "400:\ttest: 0.7265128\ttest1: 0.7187277\tbest: 0.7187281 (398)\ttotal: 23.2s\tremaining: 1m 32s\n",
      "410:\ttest: 0.7269656\ttest1: 0.7190636\tbest: 0.7191033 (405)\ttotal: 23.8s\tremaining: 1m 32s\n",
      "420:\ttest: 0.7272373\ttest1: 0.7190916\tbest: 0.7191033 (405)\ttotal: 24.4s\tremaining: 1m 31s\n",
      "430:\ttest: 0.7277787\ttest1: 0.7191842\tbest: 0.7191853 (429)\ttotal: 24.9s\tremaining: 1m 30s\n",
      "440:\ttest: 0.7284447\ttest1: 0.7195458\tbest: 0.7195458 (440)\ttotal: 25.6s\tremaining: 1m 30s\n",
      "450:\ttest: 0.7289258\ttest1: 0.7196873\tbest: 0.7196873 (450)\ttotal: 26.1s\tremaining: 1m 29s\n",
      "460:\ttest: 0.7292065\ttest1: 0.7196894\tbest: 0.7198093 (459)\ttotal: 26.7s\tremaining: 1m 29s\n",
      "470:\ttest: 0.7295766\ttest1: 0.7199834\tbest: 0.7199834 (470)\ttotal: 27.3s\tremaining: 1m 28s\n",
      "480:\ttest: 0.7300494\ttest1: 0.7201355\tbest: 0.7201355 (480)\ttotal: 27.9s\tremaining: 1m 28s\n",
      "490:\ttest: 0.7303908\ttest1: 0.7203552\tbest: 0.7203552 (490)\ttotal: 28.4s\tremaining: 1m 27s\n",
      "500:\ttest: 0.7309218\ttest1: 0.7204517\tbest: 0.7204517 (500)\ttotal: 29s\tremaining: 1m 26s\n",
      "510:\ttest: 0.7311751\ttest1: 0.7207265\tbest: 0.7207265 (510)\ttotal: 29.5s\tremaining: 1m 25s\n",
      "520:\ttest: 0.7314936\ttest1: 0.7207726\tbest: 0.7208348 (517)\ttotal: 30.1s\tremaining: 1m 25s\n",
      "530:\ttest: 0.7319036\ttest1: 0.7210959\tbest: 0.7210959 (530)\ttotal: 30.7s\tremaining: 1m 24s\n",
      "540:\ttest: 0.7321009\ttest1: 0.7212207\tbest: 0.7212492 (539)\ttotal: 31.2s\tremaining: 1m 24s\n",
      "550:\ttest: 0.7325789\ttest1: 0.7213493\tbest: 0.7213755 (546)\ttotal: 31.8s\tremaining: 1m 23s\n",
      "560:\ttest: 0.7327976\ttest1: 0.7214601\tbest: 0.7214601 (560)\ttotal: 32.4s\tremaining: 1m 23s\n",
      "570:\ttest: 0.7332450\ttest1: 0.7214884\tbest: 0.7215145 (564)\ttotal: 33s\tremaining: 1m 22s\n",
      "580:\ttest: 0.7336521\ttest1: 0.7216881\tbest: 0.7216881 (580)\ttotal: 33.5s\tremaining: 1m 21s\n",
      "590:\ttest: 0.7340931\ttest1: 0.7219952\tbest: 0.7219952 (590)\ttotal: 34.1s\tremaining: 1m 21s\n",
      "600:\ttest: 0.7343768\ttest1: 0.7221950\tbest: 0.7221950 (600)\ttotal: 34.7s\tremaining: 1m 20s\n",
      "610:\ttest: 0.7346626\ttest1: 0.7222775\tbest: 0.7222795 (609)\ttotal: 35.2s\tremaining: 1m 20s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620:\ttest: 0.7349591\ttest1: 0.7225455\tbest: 0.7225628 (615)\ttotal: 35.8s\tremaining: 1m 19s\n",
      "630:\ttest: 0.7352046\ttest1: 0.7225867\tbest: 0.7226876 (628)\ttotal: 36.5s\tremaining: 1m 19s\n",
      "640:\ttest: 0.7355468\ttest1: 0.7228033\tbest: 0.7228033 (640)\ttotal: 37.1s\tremaining: 1m 18s\n",
      "650:\ttest: 0.7357887\ttest1: 0.7229075\tbest: 0.7229075 (650)\ttotal: 37.8s\tremaining: 1m 18s\n",
      "660:\ttest: 0.7360451\ttest1: 0.7229401\tbest: 0.7229443 (659)\ttotal: 38.4s\tremaining: 1m 17s\n",
      "670:\ttest: 0.7363924\ttest1: 0.7229793\tbest: 0.7231087 (665)\ttotal: 39s\tremaining: 1m 17s\n",
      "680:\ttest: 0.7366994\ttest1: 0.7233419\tbest: 0.7233419 (680)\ttotal: 39.6s\tremaining: 1m 16s\n",
      "690:\ttest: 0.7369363\ttest1: 0.7233964\tbest: 0.7234227 (683)\ttotal: 40.1s\tremaining: 1m 15s\n",
      "700:\ttest: 0.7371983\ttest1: 0.7235591\tbest: 0.7235591 (700)\ttotal: 40.7s\tremaining: 1m 15s\n",
      "710:\ttest: 0.7375904\ttest1: 0.7235823\tbest: 0.7236915 (703)\ttotal: 41.2s\tremaining: 1m 14s\n",
      "720:\ttest: 0.7377449\ttest1: 0.7235780\tbest: 0.7236915 (703)\ttotal: 41.9s\tremaining: 1m 14s\n",
      "730:\ttest: 0.7379759\ttest1: 0.7236766\tbest: 0.7237130 (727)\ttotal: 42.5s\tremaining: 1m 13s\n",
      "740:\ttest: 0.7384379\ttest1: 0.7237201\tbest: 0.7237782 (733)\ttotal: 43.1s\tremaining: 1m 13s\n",
      "750:\ttest: 0.7386915\ttest1: 0.7237819\tbest: 0.7237819 (750)\ttotal: 43.8s\tremaining: 1m 12s\n",
      "760:\ttest: 0.7387821\ttest1: 0.7241811\tbest: 0.7241811 (760)\ttotal: 44.5s\tremaining: 1m 12s\n",
      "770:\ttest: 0.7390841\ttest1: 0.7241777\tbest: 0.7242837 (763)\ttotal: 45.1s\tremaining: 1m 11s\n",
      "780:\ttest: 0.7394969\ttest1: 0.7242938\tbest: 0.7243233 (777)\ttotal: 45.7s\tremaining: 1m 11s\n",
      "790:\ttest: 0.7397947\ttest1: 0.7244649\tbest: 0.7244649 (790)\ttotal: 46.3s\tremaining: 1m 10s\n",
      "800:\ttest: 0.7401868\ttest1: 0.7244462\tbest: 0.7245555 (797)\ttotal: 46.9s\tremaining: 1m 10s\n",
      "810:\ttest: 0.7404487\ttest1: 0.7244175\tbest: 0.7247076 (809)\ttotal: 47.5s\tremaining: 1m 9s\n",
      "820:\ttest: 0.7406381\ttest1: 0.7247582\tbest: 0.7247823 (816)\ttotal: 48.1s\tremaining: 1m 9s\n",
      "830:\ttest: 0.7408865\ttest1: 0.7248927\tbest: 0.7248927 (830)\ttotal: 48.7s\tremaining: 1m 8s\n",
      "840:\ttest: 0.7411409\ttest1: 0.7247799\tbest: 0.7248927 (830)\ttotal: 49.3s\tremaining: 1m 8s\n",
      "850:\ttest: 0.7414087\ttest1: 0.7248969\tbest: 0.7249355 (847)\ttotal: 50s\tremaining: 1m 7s\n",
      "860:\ttest: 0.7416241\ttest1: 0.7251531\tbest: 0.7251531 (860)\ttotal: 50.5s\tremaining: 1m 6s\n",
      "870:\ttest: 0.7419127\ttest1: 0.7251983\tbest: 0.7252065 (865)\ttotal: 51.1s\tremaining: 1m 6s\n",
      "880:\ttest: 0.7421743\ttest1: 0.7253464\tbest: 0.7253464 (880)\ttotal: 51.6s\tremaining: 1m 5s\n",
      "890:\ttest: 0.7424395\ttest1: 0.7253323\tbest: 0.7253851 (883)\ttotal: 52.2s\tremaining: 1m 4s\n",
      "900:\ttest: 0.7426815\ttest1: 0.7252940\tbest: 0.7253851 (883)\ttotal: 52.8s\tremaining: 1m 4s\n",
      "910:\ttest: 0.7429202\ttest1: 0.7253040\tbest: 0.7253851 (883)\ttotal: 53.4s\tremaining: 1m 3s\n",
      "920:\ttest: 0.7430664\ttest1: 0.7252934\tbest: 0.7253884 (917)\ttotal: 53.9s\tremaining: 1m 3s\n",
      "930:\ttest: 0.7432911\ttest1: 0.7254176\tbest: 0.7254349 (928)\ttotal: 54.5s\tremaining: 1m 2s\n",
      "940:\ttest: 0.7434868\ttest1: 0.7254275\tbest: 0.7254806 (937)\ttotal: 55.1s\tremaining: 1m 2s\n",
      "950:\ttest: 0.7438400\ttest1: 0.7253076\tbest: 0.7254806 (937)\ttotal: 55.7s\tremaining: 1m 1s\n",
      "960:\ttest: 0.7440099\ttest1: 0.7253534\tbest: 0.7254806 (937)\ttotal: 56.3s\tremaining: 1m\n",
      "970:\ttest: 0.7443353\ttest1: 0.7253218\tbest: 0.7254806 (937)\ttotal: 56.8s\tremaining: 1m\n",
      "980:\ttest: 0.7445562\ttest1: 0.7253575\tbest: 0.7254806 (937)\ttotal: 57.4s\tremaining: 59.6s\n",
      "990:\ttest: 0.7448197\ttest1: 0.7255277\tbest: 0.7255352 (986)\ttotal: 57.9s\tremaining: 59s\n",
      "1000:\ttest: 0.7452140\ttest1: 0.7255676\tbest: 0.7255970 (997)\ttotal: 58.5s\tremaining: 58.4s\n",
      "1010:\ttest: 0.7455047\ttest1: 0.7255672\tbest: 0.7256417 (1003)\ttotal: 59.1s\tremaining: 57.8s\n",
      "1020:\ttest: 0.7457083\ttest1: 0.7257941\tbest: 0.7257941 (1020)\ttotal: 59.7s\tremaining: 57.2s\n",
      "1030:\ttest: 0.7459800\ttest1: 0.7258709\tbest: 0.7258801 (1029)\ttotal: 1m\tremaining: 56.6s\n",
      "1040:\ttest: 0.7461649\ttest1: 0.7259834\tbest: 0.7259949 (1038)\ttotal: 1m\tremaining: 56s\n",
      "1050:\ttest: 0.7465450\ttest1: 0.7260115\tbest: 0.7260530 (1043)\ttotal: 1m 1s\tremaining: 55.5s\n",
      "1060:\ttest: 0.7468296\ttest1: 0.7260262\tbest: 0.7260654 (1056)\ttotal: 1m 1s\tremaining: 54.9s\n",
      "1070:\ttest: 0.7470675\ttest1: 0.7262145\tbest: 0.7262474 (1068)\ttotal: 1m 2s\tremaining: 54.3s\n",
      "1080:\ttest: 0.7472660\ttest1: 0.7263129\tbest: 0.7263129 (1080)\ttotal: 1m 3s\tremaining: 53.7s\n",
      "1090:\ttest: 0.7474693\ttest1: 0.7261816\tbest: 0.7263129 (1080)\ttotal: 1m 3s\tremaining: 53.1s\n",
      "1100:\ttest: 0.7477145\ttest1: 0.7258606\tbest: 0.7263129 (1080)\ttotal: 1m 4s\tremaining: 52.4s\n",
      "1110:\ttest: 0.7479266\ttest1: 0.7258796\tbest: 0.7263129 (1080)\ttotal: 1m 4s\tremaining: 51.9s\n",
      "1120:\ttest: 0.7481564\ttest1: 0.7259583\tbest: 0.7263129 (1080)\ttotal: 1m 5s\tremaining: 51.3s\n",
      "1130:\ttest: 0.7484269\ttest1: 0.7261364\tbest: 0.7263129 (1080)\ttotal: 1m 5s\tremaining: 50.7s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7263129091\n",
      "bestIteration = 1080\n",
      "\n",
      "Shrink model to first 1081 iterations.\n",
      "Fold 5, Valid score = 0.72631\n",
      "Score by each fold: [0.72311, 0.72479, 0.72903, 0.72157, 0.72631]\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "cb_params = {\n",
    "    \"n_estimators\": 2000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"max_bin\": 20,\n",
    "    \"verbose\": 10,\n",
    "    \"max_depth\": 6,\n",
    "    \"l2_leaf_reg\": 10,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"thread_count\": 6,\n",
    "    \"random_seed\": seed\n",
    "}\n",
    "\n",
    "cb_estimators, cb_oof_preds = catboost_cross_validation(\n",
    "    params=cb_params, X=train_encode, y=target, cv=cv, categorical=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb11abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.724\n"
     ]
    }
   ],
   "source": [
    "# Score by each fold: [0.72311, 0.72479, 0.72903, 0.72157, 0.72631]\n",
    "\n",
    "cb_oof_score = roc_auc_score(\n",
    "    target, cb_oof_preds\n",
    ")\n",
    "print(f\"OOF-score = {round(cb_oof_score, 5)}\")\n",
    "# OOF-score = 0.724"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3638c2",
   "metadata": {},
   "source": [
    "### Prediction Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "327ca177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-b84d79650ff7>:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask = np.zeros_like(corr_3, dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "scores_3 = pd.DataFrame({\n",
    "    \"lgbm\": lgbm_oof_preds,\n",
    "    \"xgb\": xgb_oof_preds,\n",
    "    \"cat\": cb_oof_preds,\n",
    "})\n",
    "\n",
    "corr_3 = scores_3.corr()\n",
    "mask = np.zeros_like(corr_3, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a17788a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 8))\n",
    "sns.heatmap(corr_3, mask=mask, annot=True, fmt=\".4g\", square=True, cmap=\"viridis\", ax=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0fe35d",
   "metadata": {},
   "source": [
    "### Test Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6be23814",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_test_preds  = predict_by_estimators(test_encode, cb_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67ea6e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-5a1da3b8fed1>:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask = np.zeros_like(corr_test_3, dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "scores_test_3 = pd.DataFrame({\n",
    "    \"lgbm\": lgbm_test_preds[\"TARGET\"],\n",
    "    \"xgb\": xgb_test_preds[\"TARGET\"],\n",
    "    \"cat\": cb_test_preds[\"TARGET\"],\n",
    "})\n",
    "\n",
    "corr_test_3 = scores_test_3.corr()\n",
    "mask = np.zeros_like(corr_test_3, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bedd8f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 8))\n",
    "sns.heatmap(corr_test_3, mask=mask, annot=True, fmt=\".4g\", square=True, cmap=\"viridis\", ax=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0316c8c",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "* Наблюдается высокая корреляция между рассматриваемыми тремя моделями, что свидетельствует о схожей предсказательной силе.\n",
    "* Корреляция между моделями на тестовой выборке выше, чем на обучающей выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44904c79",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "Выполнить задание 2 для трех моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7664db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMean Score = 0.72642\n",
      "GMean Score = 0.72644\n",
      "Rankdata Score = 0.72638\n",
      "GMean Rankdata Score = 0.72637\n"
     ]
    }
   ],
   "source": [
    "scores_amean = scores_3.mean(axis=1)\n",
    "auc_amean = roc_auc_score(target, scores_amean)\n",
    "print(f\"AMean Score = {round(auc_amean, 5)}\")\n",
    "\n",
    "scores_gmean = gmean(scores_3, axis=1)\n",
    "auc_gmean = roc_auc_score(target, scores_gmean)\n",
    "print(f\"GMean Score = {round(auc_gmean, 5)}\")\n",
    "\n",
    "scores_rankdata = scores_3.rank().mean(axis=1)\n",
    "auc_rankdata = roc_auc_score(target, scores_rankdata)\n",
    "print(f\"Rankdata Score = {round(auc_rankdata, 5)}\")\n",
    "\n",
    "scores_gmean_rankdata = gmean(scores_3.rank(), axis=1)\n",
    "auc_gmean_rankdata = roc_auc_score(target, scores_gmean_rankdata)\n",
    "print(f\"GMean Rankdata Score = {round(auc_gmean_rankdata, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef0ecb",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "* Качество на одиночных моделях составляет: LightGBM - 0.72286, XGBoost - 0.72668, Catboost - 0.724\n",
    "* Качество усредненных прогнозов AMean - 0.72642, GMean - 0.72644, Rankdata - 0.72638, GMean Rankdata - 0.72637\n",
    "* Усредненные прогнозы по трем моделям имеют незначительные различия качества метрики. \n",
    "* Качество одиночной модели XGBoost немного выше качества метрики усредненных прогнозов по трем моделям. \n",
    "* Качествоусредненных прогнозов по трем моделям выше качества усредненных прогнозов по двум моделям."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc5fe19",
   "metadata": {},
   "source": [
    "## Задание 5. (опция)\n",
    "Объединить OOF-прогнозы для трех моделей и обучить алгоритм Логистической регрессии (и любой другой, на ваше усмотрение). Сделать выводы о достигаемом качестве, сравнить достигаемое качество с качеством отдельных моделей и моделей, полученных в п.2 и п.4.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "154a687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e7bf4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_cross_validation(model, X, y, cv):\n",
    "    \"\"\"\n",
    "    Кросс-валидация для логистической регрессии.\n",
    "\n",
    "    \"\"\"\n",
    "      \n",
    "    estimators, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "\n",
    "    print(f\"{time.ctime()}, Cross-Validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "\n",
    "    X = X.fillna(-1)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "        \n",
    " \n",
    "        model.fit(X=x_train, y=y_train)\n",
    "    \n",
    "        oof_preds[valid_idx] = model.predict_proba(x_valid)[:, 1]\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimators.append(model)\n",
    "               \n",
    "            \n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    return estimators, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdd39fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof_preds = pd.DataFrame(np.vstack((lgbm_oof_preds, xgb_oof_preds, cb_oof_preds)).T,\n",
    "                                columns=['lgbm', 'xgb', 'cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e1a1d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm</th>\n",
       "      <th>xgb</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019668</td>\n",
       "      <td>0.018412</td>\n",
       "      <td>0.027537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.085944</td>\n",
       "      <td>0.086530</td>\n",
       "      <td>0.085758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056040</td>\n",
       "      <td>0.057675</td>\n",
       "      <td>0.058633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.192507</td>\n",
       "      <td>0.160854</td>\n",
       "      <td>0.204327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.082735</td>\n",
       "      <td>0.082997</td>\n",
       "      <td>0.082617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lgbm       xgb       cat\n",
       "0  0.019668  0.018412  0.027537\n",
       "1  0.085944  0.086530  0.085758\n",
       "2  0.056040  0.057675  0.058633\n",
       "3  0.192507  0.160854  0.204327\n",
       "4  0.082735  0.082997  0.082617"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oof_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65f86ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 30 23:06:05 2021, Cross-Validation, 110093 rows, 3 cols\n",
      "Fold 1, Valid score = 0.72314\n",
      "Fold 2, Valid score = 0.7281\n",
      "Fold 3, Valid score = 0.73396\n",
      "Fold 4, Valid score = 0.72556\n",
      "Fold 5, Valid score = 0.72903\n",
      "Score by each fold: [0.72314, 0.7281, 0.73396, 0.72556, 0.72903]\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(random_state=seed, solver=\"liblinear\")\n",
    "\n",
    "lr_estimators, lr_oof_preds = lr_cross_validation(model=lr_clf,\n",
    "                                                 X=train_oof_preds,\n",
    "                                                 y=target,\n",
    "                                                 cv=cv\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46428743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.72678\n"
     ]
    }
   ],
   "source": [
    "lr_oof_score = roc_auc_score(target, lr_oof_preds)\n",
    "print(f\"OOF-score = {round(lr_oof_score, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81fdbe",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "* Качество на одиночных моделях составляет: LightGBM - 0.72286, XGBoost - 0.72668, Catboost - 0.724\n",
    "* Качество усредненных прогнозов AMean - 0.72642, GMean - 0.72644, Rankdata - 0.72638, GMean Rankdata - 0.72637\n",
    "* Качество Логистической регрессии, построенной на трех моделях, составляет 0.72678, что немногим выше, чем качество одиночных и усредненных прогнозов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d1c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
